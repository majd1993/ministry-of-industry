{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = createMultiBufferingPlayer; // Currently, Web Chat uses a triple-buffer approach.\n\nvar NUM_BUFFER = 3;\n\nfunction zeroBuffer(buffer) {\n  var channels = buffer.numberOfChannels;\n\n  for (var channel = 0; channel < channels; channel++) {\n    var audioData = buffer.getChannelData(channel);\n    [].fill.call(audioData, 0);\n  }\n}\n\nfunction copyBuffer(buffer, multiChannelArray) {\n  var channels = buffer.numberOfChannels;\n\n  for (var channel = 0; channel < channels; channel++) {\n    var float32Array = multiChannelArray[channel]; // Note that Safari does not support AudioBuffer.copyToChannel yet.\n\n    if (buffer.copyToChannel) {\n      buffer.copyToChannel(float32Array, channel);\n    } else {\n      var float32ArrayLength = float32Array.length;\n      var perChannelBuffer = buffer.getChannelData(channel);\n\n      for (var offset = 0; offset < float32ArrayLength; offset++) {\n        perChannelBuffer[offset] = float32Array[offset];\n      }\n    }\n  }\n} // This is a multi-buffering player. Users can keep pushing buffer to Web Chat.\n// The buffer, realized as BufferSource, is queued to AudioContext.\n// Data will be queued as quickly and frequently as possible.\n// Web Chat does not support progressive buffering (pushing a partial buffer) and there are currently no plans to implement.\n\n\nfunction createMultiBufferingPlayer(audioContext, _ref, numSamplePerBuffer) {\n  var channels = _ref.channels,\n      samplesPerSec = _ref.samplesPerSec;\n  var freeBuffers = new Array(NUM_BUFFER).fill().map(function () {\n    return audioContext.createBuffer(channels, numSamplePerBuffer, samplesPerSec);\n  });\n  var queuedBufferSources = [];\n  var nextSchedule;\n  var queue = [];\n\n  var playNext = function playNext() {\n    if (typeof nextSchedule !== 'number') {\n      nextSchedule = audioContext.currentTime;\n    }\n\n    var bufferSource = audioContext.createBufferSource();\n    var multiChannelArray = queue.shift();\n\n    if (typeof multiChannelArray === 'function') {\n      // If the queued item is a function, it is because the user called \"flush\".\n      // The \"flush\" function will callback when all queued buffers before the \"flush\" call have played.\n      multiChannelArray();\n    } else if (multiChannelArray) {\n      var nextBuffer = freeBuffers.shift(); // If all buffers are currently occupied, prepend the data back to the queue.\n      // When one of the buffers finish, it will call playNext() again to pick up items from the queue.\n\n      if (!nextBuffer) {\n        queue.unshift(multiChannelArray);\n        return;\n      }\n\n      zeroBuffer(nextBuffer);\n      copyBuffer(nextBuffer, multiChannelArray);\n      bufferSource.buffer = nextBuffer;\n      bufferSource.connect(audioContext.destination);\n      bufferSource.start(nextSchedule); // All BufferSource data that is currently queued will be stored at the AudioContext, via bufferSource.start().\n      // This is for cancelAll() to effectively cancel all BufferSource queued at the AudioContext.\n\n      queuedBufferSources.push(bufferSource);\n      nextSchedule += nextBuffer.duration;\n      bufferSource.addEventListener('ended', function () {\n        queuedBufferSources = queuedBufferSources.filter(function (target) {\n          return target !== bufferSource;\n        }); // Declare the buffer is free to pick up on the next iteration.\n\n        freeBuffers.push(nextBuffer);\n        playNext();\n      });\n    }\n  };\n\n  return {\n    cancelAll: function cancelAll() {\n      queue.splice(0); // Although all buffers are cleared, there are still some BufferSources queued at the AudioContext that need to be stopped.\n\n      queuedBufferSources.forEach(function (bufferSource) {\n        return bufferSource.stop();\n      });\n    },\n    flush: function flush() {\n      return new Promise(function (resolve) {\n        return queue.push(resolve);\n      });\n    },\n    push: function push(multiChannelArray) {\n      if (!multiChannelArray) {\n        throw new Error('multiChannelArray must not be falsy.');\n      }\n\n      queue.push(multiChannelArray);\n      playNext();\n    }\n  };\n}","map":{"version":3,"sources":["../src/createMultiBufferingPlayer.js"],"names":["NUM_BUFFER","channels","buffer","channel","audioData","float32Array","multiChannelArray","float32ArrayLength","perChannelBuffer","offset","samplesPerSec","freeBuffers","audioContext","queuedBufferSources","queue","playNext","nextSchedule","bufferSource","nextBuffer","zeroBuffer","copyBuffer","target","cancelAll","flush","push"],"mappings":";;;;;8CAAA;;AACA,IAAMA,UAAU,GAAhB,CAAA;;AAEA,SAAA,UAAA,CAAA,MAAA,EAA4B;AAC1B,MAAMC,QAAQ,GAAGC,MAAM,CAAvB,gBAAA;;AAEA,OAAK,IAAIC,OAAO,GAAhB,CAAA,EAAsBA,OAAO,GAA7B,QAAA,EAA0CA,OAA1C,EAAA,EAAqD;AACnD,QAAMC,SAAS,GAAGF,MAAM,CAANA,cAAAA,CAAlB,OAAkBA,CAAlB;AAEA,OAAA,IAAA,CAAA,IAAA,CAAA,SAAA,EAAA,CAAA;AACD;AACF;;AAED,SAAA,UAAA,CAAA,MAAA,EAAA,iBAAA,EAA+C;AAC7C,MAAMD,QAAQ,GAAGC,MAAM,CAAvB,gBAAA;;AAEA,OAAK,IAAIC,OAAO,GAAhB,CAAA,EAAsBA,OAAO,GAA7B,QAAA,EAA0CA,OAA1C,EAAA,EAAqD;AACnD,QAAME,YAAY,GAAGC,iBAAiB,CADa,OACb,CAAtC,CADmD,CAGnD;;AACA,QAAIJ,MAAM,CAAV,aAAA,EAA0B;AACxBA,MAAAA,MAAM,CAANA,aAAAA,CAAAA,YAAAA,EAAAA,OAAAA;AADF,KAAA,MAEO;AAAA,UACWK,kBADX,GACkCF,YADlC,CAAA,MAAA;AAEL,UAAMG,gBAAgB,GAAGN,MAAM,CAANA,cAAAA,CAAzB,OAAyBA,CAAzB;;AAEA,WAAK,IAAIO,MAAM,GAAf,CAAA,EAAqBA,MAAM,GAA3B,kBAAA,EAAkDA,MAAlD,EAAA,EAA4D;AAC1DD,QAAAA,gBAAgB,CAAhBA,MAAgB,CAAhBA,GAA2BH,YAAY,CAAvCG,MAAuC,CAAvCA;AACD;AACF;AACF;EAGH;AACA;AACA;AACA;;;AAEe,SAAA,0BAAA,CAAA,YAAA,EAAA,IAAA,EAAA,kBAAA,EAAmG;AAAA,MAA/CP,QAA+C,GAAA,IAAA,CAA/CA,QAA+C;AAAA,MAArCS,aAAqC,GAAA,IAAA,CAArCA,aAAqC;AAChH,MAAMC,WAAW,GAAG,IAAA,KAAA,CAAA,UAAA,EAAA,IAAA,GAAA,GAAA,CAEb,YAAA;AAAA,WAAMC,YAAY,CAAZA,YAAAA,CAAAA,QAAAA,EAAAA,kBAAAA,EAAN,aAAMA,CAAN;AAFP,GAAoB,CAApB;AAGA,MAAIC,mBAAmB,GAAvB,EAAA;AACA,MAAA,YAAA;AAEA,MAAMC,KAAK,GAAX,EAAA;;AAEA,MAAMC,QAAQ,GAAG,SAAXA,QAAW,GAAM;AACrB,QAAI,OAAA,YAAA,KAAJ,QAAA,EAAsC;AACpCC,MAAAA,YAAY,GAAGJ,YAAY,CAA3BI,WAAAA;AACD;;AAED,QAAMC,YAAY,GAAGL,YAAY,CAAjC,kBAAqBA,EAArB;AACA,QAAMN,iBAAiB,GAAGQ,KAAK,CAA/B,KAA0BA,EAA1B;;AAEA,QAAI,OAAA,iBAAA,KAAJ,UAAA,EAA6C;AAC3C;AACA;AACAR,MAAAA,iBAAiB;AAHnB,KAAA,MAIO,IAAA,iBAAA,EAAuB;AAC5B,UAAMY,UAAU,GAAGP,WAAW,CADF,KACTA,EAAnB,CAD4B,CAG5B;AACA;;AACA,UAAI,CAAJ,UAAA,EAAiB;AACfG,QAAAA,KAAK,CAALA,OAAAA,CAAAA,iBAAAA;AAEA;AACD;;AAEDK,MAAAA,UAAU,CAAVA,UAAU,CAAVA;AACAC,MAAAA,UAAU,CAAA,UAAA,EAAVA,iBAAU,CAAVA;AAEAH,MAAAA,YAAY,CAAZA,MAAAA,GAAAA,UAAAA;AACAA,MAAAA,YAAY,CAAZA,OAAAA,CAAqBL,YAAY,CAAjCK,WAAAA;AACAA,MAAAA,YAAY,CAAZA,KAAAA,CAhB4B,YAgB5BA,EAhB4B,CAkB5B;AACA;;AACAJ,MAAAA,mBAAmB,CAAnBA,IAAAA,CAAAA,YAAAA;AAEAG,MAAAA,YAAY,IAAIE,UAAU,CAA1BF,QAAAA;AAEAC,MAAAA,YAAY,CAAZA,gBAAAA,CAAAA,OAAAA,EAAuC,YAAM;AAC3CJ,QAAAA,mBAAmB,GAAG,mBAAmB,CAAnB,MAAA,CAA2B,UAAA,MAAA,EAAM;AAAA,iBAAIQ,MAAM,KAAV,YAAA;AADZ,SACrB,CAAtBR,CAD2C,CAG3C;;AACAF,QAAAA,WAAW,CAAXA,IAAAA,CAAAA,UAAAA;AACAI,QAAAA,QAAQ;AALVE,OAAAA;AAOD;AA3CH,GAAA;;AA8CA,SAAO;AACLK,IAAAA,SAAS,EAAE,SAAA,SAAA,GAAM;AACfR,MAAAA,KAAK,CAALA,MAAAA,CADe,CACfA,EADe,CAGf;;AACAD,MAAAA,mBAAmB,CAAnBA,OAAAA,CAA4B,UAAA,YAAA,EAAY;AAAA,eAAII,YAAY,CAAhB,IAAIA,EAAJ;AAAxCJ,OAAAA;AALG,KAAA;AAOLU,IAAAA,KAAK,EAAE,SAAA,KAAA,GAAA;AAAA,aAAM,IAAA,OAAA,CAAY,UAAA,OAAA,EAAO;AAAA,eAAIT,KAAK,CAALA,IAAAA,CAAJ,OAAIA,CAAJ;AAAzB,OAAM,CAAN;AAPF,KAAA;AAQLU,IAAAA,IAAI,EAAE,SAAA,IAAA,CAAA,iBAAA,EAAqB;AACzB,UAAI,CAAJ,iBAAA,EAAwB;AACtB,cAAM,IAAA,KAAA,CAAN,sCAAM,CAAN;AACD;;AAEDV,MAAAA,KAAK,CAALA,IAAAA,CAAAA,iBAAAA;AAEAC,MAAAA,QAAQ;AACT;AAhBI,GAAP;AAkBD","sourcesContent":["// Currently, Web Chat uses a triple-buffer approach.\nconst NUM_BUFFER = 3;\n\nfunction zeroBuffer(buffer) {\n  const channels = buffer.numberOfChannels;\n\n  for (let channel = 0; channel < channels; channel++) {\n    const audioData = buffer.getChannelData(channel);\n\n    [].fill.call(audioData, 0);\n  }\n}\n\nfunction copyBuffer(buffer, multiChannelArray) {\n  const channels = buffer.numberOfChannels;\n\n  for (let channel = 0; channel < channels; channel++) {\n    const float32Array = multiChannelArray[channel];\n\n    // Note that Safari does not support AudioBuffer.copyToChannel yet.\n    if (buffer.copyToChannel) {\n      buffer.copyToChannel(float32Array, channel);\n    } else {\n      const { length: float32ArrayLength } = float32Array;\n      const perChannelBuffer = buffer.getChannelData(channel);\n\n      for (let offset = 0; offset < float32ArrayLength; offset++) {\n        perChannelBuffer[offset] = float32Array[offset];\n      }\n    }\n  }\n}\n\n// This is a multi-buffering player. Users can keep pushing buffer to Web Chat.\n// The buffer, realized as BufferSource, is queued to AudioContext.\n// Data will be queued as quickly and frequently as possible.\n// Web Chat does not support progressive buffering (pushing a partial buffer) and there are currently no plans to implement.\n\nexport default function createMultiBufferingPlayer(audioContext, { channels, samplesPerSec }, numSamplePerBuffer) {\n  const freeBuffers = new Array(NUM_BUFFER)\n    .fill()\n    .map(() => audioContext.createBuffer(channels, numSamplePerBuffer, samplesPerSec));\n  let queuedBufferSources = [];\n  let nextSchedule;\n\n  const queue = [];\n\n  const playNext = () => {\n    if (typeof nextSchedule !== 'number') {\n      nextSchedule = audioContext.currentTime;\n    }\n\n    const bufferSource = audioContext.createBufferSource();\n    const multiChannelArray = queue.shift();\n\n    if (typeof multiChannelArray === 'function') {\n      // If the queued item is a function, it is because the user called \"flush\".\n      // The \"flush\" function will callback when all queued buffers before the \"flush\" call have played.\n      multiChannelArray();\n    } else if (multiChannelArray) {\n      const nextBuffer = freeBuffers.shift();\n\n      // If all buffers are currently occupied, prepend the data back to the queue.\n      // When one of the buffers finish, it will call playNext() again to pick up items from the queue.\n      if (!nextBuffer) {\n        queue.unshift(multiChannelArray);\n\n        return;\n      }\n\n      zeroBuffer(nextBuffer);\n      copyBuffer(nextBuffer, multiChannelArray);\n\n      bufferSource.buffer = nextBuffer;\n      bufferSource.connect(audioContext.destination);\n      bufferSource.start(nextSchedule);\n\n      // All BufferSource data that is currently queued will be stored at the AudioContext, via bufferSource.start().\n      // This is for cancelAll() to effectively cancel all BufferSource queued at the AudioContext.\n      queuedBufferSources.push(bufferSource);\n\n      nextSchedule += nextBuffer.duration;\n\n      bufferSource.addEventListener('ended', () => {\n        queuedBufferSources = queuedBufferSources.filter(target => target !== bufferSource);\n\n        // Declare the buffer is free to pick up on the next iteration.\n        freeBuffers.push(nextBuffer);\n        playNext();\n      });\n    }\n  };\n\n  return {\n    cancelAll: () => {\n      queue.splice(0);\n\n      // Although all buffers are cleared, there are still some BufferSources queued at the AudioContext that need to be stopped.\n      queuedBufferSources.forEach(bufferSource => bufferSource.stop());\n    },\n    flush: () => new Promise(resolve => queue.push(resolve)),\n    push: multiChannelArray => {\n      if (!multiChannelArray) {\n        throw new Error('multiChannelArray must not be falsy.');\n      }\n\n      queue.push(multiChannelArray);\n\n      playNext();\n    }\n  };\n}\n"],"sourceRoot":"directlinespeech:///"},"metadata":{},"sourceType":"script"}