{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports[\"default\"] = createNativeUtterance;\n\nfunction createNativeUtterance(_ref, _ref2) {\n  var speechSynthesis = _ref.speechSynthesis,\n      SpeechSynthesisUtterance = _ref.SpeechSynthesisUtterance;\n  var lang = _ref2.lang,\n      onBoundary = _ref2.onBoundary,\n      pitch = _ref2.pitch,\n      rate = _ref2.rate,\n      text = _ref2.text,\n      voice = _ref2.voice,\n      volume = _ref2.volume;\n  var utterance = new SpeechSynthesisUtterance(text);\n  var targetVoice;\n\n  if (typeof voice === 'function') {\n    targetVoice = voice.call(speechSynthesis, speechSynthesis.getVoices());\n  } else {\n    var _ref3 = voice || {},\n        voiceURI = _ref3.voiceURI;\n\n    targetVoice = voiceURI && [].find.call([].slice.call(speechSynthesis.getVoices()), function (v) {\n      return v.voiceURI === voiceURI;\n    });\n  } // Edge will mute if \"lang\" is set to \"\"\n\n\n  utterance.lang = lang || '';\n\n  if (pitch || pitch === 0) {\n    utterance.pitch = pitch;\n  }\n\n  if (rate || rate === 0) {\n    utterance.rate = rate;\n  } // Cognitive Services will error when \"voice\" is set to \"null\"\n  // Edge will error when \"voice\" is set to \"undefined\"\n\n\n  if (targetVoice) {\n    utterance.voice = targetVoice;\n  }\n\n  if (volume || volume === 0) {\n    utterance.volume = volume;\n  } // Since browser quirks, start/error/end events are emulated for best compatibility\n  // start/error/end events are emulated in QueuedUtterance\n\n\n  onBoundary && utterance.addEventListener('boundary', onBoundary); // onEnd && utterance.addEventListener('end', onEnd);\n  // onError && utterance.addEventListener('error', onError);\n  // onStart && utterance.addEventListener('start', onStart);\n\n  return utterance;\n}","map":{"version":3,"sources":["../src/createNativeUtterance.js"],"names":["speechSynthesis","SpeechSynthesisUtterance","lang","onBoundary","pitch","rate","text","voice","volume","utterance","targetVoice","voiceURI","v"],"mappings":";;;;;;;AAAe,SAAA,qBAAA,CAAA,IAAA,EAAA,KAAA,EAcb;AAAA,MAZEA,eAYF,GAAA,IAAA,CAZEA,eAYF;AAAA,MAXEC,wBAWF,GAAA,IAAA,CAXEA,wBAWF;AAAA,MAREC,IAQF,GAAA,KAAA,CAREA,IAQF;AAAA,MAPEC,UAOF,GAAA,KAAA,CAPEA,UAOF;AAAA,MANEC,KAMF,GAAA,KAAA,CANEA,KAMF;AAAA,MALEC,IAKF,GAAA,KAAA,CALEA,IAKF;AAAA,MAJEC,IAIF,GAAA,KAAA,CAJEA,IAIF;AAAA,MAHEC,KAGF,GAAA,KAAA,CAHEA,KAGF;AAAA,MAFEC,MAEF,GAAA,KAAA,CAFEA,MAEF;AACA,MAAMC,SAAS,GAAG,IAAA,wBAAA,CAAlB,IAAkB,CAAlB;AACA,MAAA,WAAA;;AAEA,MAAI,OAAA,KAAA,KAAJ,UAAA,EAAiC;AAC/BC,IAAAA,WAAW,GAAGH,KAAK,CAALA,IAAAA,CAAAA,eAAAA,EAA4BP,eAAe,CAAzDU,SAA0CV,EAA5BO,CAAdG;AADF,GAAA,MAEO;AAAA,QAAA,KAAA,GACgBH,KAAK,IADrB,EAAA;AAAA,QACGI,QADH,GAAA,KAAA,CAAA,QAAA;;AAGLD,IAAAA,WAAW,GAAGC,QAAQ,IAAI,GAAA,IAAA,CAAA,IAAA,CAAa,GAAA,KAAA,CAAA,IAAA,CAAcX,eAAe,CAA1C,SAA2BA,EAAd,CAAb,EAAyD,UAAA,CAAA,EAAC;AAAA,aAAIY,CAAC,CAADA,QAAAA,KAAJ,QAAA;AAApFF,KAA0B,CAA1BA;AATF,GAAA,CAYA;;;AACAD,EAAAA,SAAS,CAATA,IAAAA,GAAiBP,IAAI,IAArBO,EAAAA;;AAEA,MAAIL,KAAK,IAAIA,KAAK,KAAlB,CAAA,EAA0B;AACxBK,IAAAA,SAAS,CAATA,KAAAA,GAAAA,KAAAA;AACD;;AAED,MAAIJ,IAAI,IAAIA,IAAI,KAAhB,CAAA,EAAwB;AACtBI,IAAAA,SAAS,CAATA,IAAAA,GAAAA,IAAAA;AApBF,GAAA,CAuBA;AACA;;;AACA,MAAA,WAAA,EAAiB;AACfA,IAAAA,SAAS,CAATA,KAAAA,GAAAA,WAAAA;AACD;;AAED,MAAID,MAAM,IAAIA,MAAM,KAApB,CAAA,EAA4B;AAC1BC,IAAAA,SAAS,CAATA,MAAAA,GAAAA,MAAAA;AA9BF,GAAA,CAiCA;AACA;;;AAEAN,EAAAA,UAAU,IAAIM,SAAS,CAATA,gBAAAA,CAAAA,UAAAA,EApCd,UAoCcA,CAAdN,CApCA,CAqCA;AACA;AACA;;AAEA,SAAA,SAAA;AACD","sourcesContent":["export default function createNativeUtterance(\n  {\n    speechSynthesis,\n    SpeechSynthesisUtterance\n  },\n  {\n    lang,\n    onBoundary,\n    pitch,\n    rate,\n    text,\n    voice,\n    volume\n  }\n) {\n  const utterance = new SpeechSynthesisUtterance(text);\n  let targetVoice;\n\n  if (typeof voice === 'function') {\n    targetVoice = voice.call(speechSynthesis, speechSynthesis.getVoices());\n  } else {\n    const { voiceURI } = voice || {};\n\n    targetVoice = voiceURI && [].find.call([].slice.call(speechSynthesis.getVoices()), v => v.voiceURI === voiceURI);\n  }\n\n  // Edge will mute if \"lang\" is set to \"\"\n  utterance.lang = lang || '';\n\n  if (pitch || pitch === 0) {\n    utterance.pitch = pitch;\n  }\n\n  if (rate || rate === 0) {\n    utterance.rate = rate;\n  }\n\n  // Cognitive Services will error when \"voice\" is set to \"null\"\n  // Edge will error when \"voice\" is set to \"undefined\"\n  if (targetVoice) {\n    utterance.voice = targetVoice;\n  }\n\n  if (volume || volume === 0) {\n    utterance.volume = volume;\n  }\n\n  // Since browser quirks, start/error/end events are emulated for best compatibility\n  // start/error/end events are emulated in QueuedUtterance\n\n  onBoundary && utterance.addEventListener('boundary', onBoundary);\n  // onEnd && utterance.addEventListener('end', onEnd);\n  // onError && utterance.addEventListener('error', onError);\n  // onStart && utterance.addEventListener('start', onStart);\n\n  return utterance;\n}\n"]},"metadata":{},"sourceType":"script"}