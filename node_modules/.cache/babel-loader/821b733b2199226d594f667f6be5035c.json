{"ast":null,"code":"\"use strict\";\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\");\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\n\nvar _regenerator = _interopRequireDefault(require(\"@babel/runtime/regenerator\"));\n\nvar _asyncToGenerator2 = _interopRequireDefault(require(\"@babel/runtime/helpers/asyncToGenerator\"));\n\nvar _classCallCheck2 = _interopRequireDefault(require(\"@babel/runtime/helpers/classCallCheck\"));\n\nvar _createClass2 = _interopRequireDefault(require(\"@babel/runtime/helpers/createClass\"));\n\nvar _inherits2 = _interopRequireDefault(require(\"@babel/runtime/helpers/inherits\"));\n\nvar _possibleConstructorReturn2 = _interopRequireDefault(require(\"@babel/runtime/helpers/possibleConstructorReturn\"));\n\nvar _getPrototypeOf2 = _interopRequireDefault(require(\"@babel/runtime/helpers/getPrototypeOf\"));\n\nvar _eventTargetShimEs = require(\"event-target-shim-es5\");\n\nvar _eventAsPromise = _interopRequireDefault(require(\"event-as-promise\"));\n\nvar _fetchSpeechData = _interopRequireDefault(require(\"./fetchSpeechData\"));\n\nvar _SpeechSynthesisEvent = _interopRequireDefault(require(\"./SpeechSynthesisEvent\"));\n\nvar _subscribeEvent = _interopRequireDefault(require(\"./subscribeEvent\"));\n\nfunction _createSuper(Derived) {\n  var hasNativeReflectConstruct = _isNativeReflectConstruct();\n\n  return function () {\n    var Super = (0, _getPrototypeOf2.default)(Derived),\n        result;\n\n    if (hasNativeReflectConstruct) {\n      var NewTarget = (0, _getPrototypeOf2.default)(this).constructor;\n      result = Reflect.construct(Super, arguments, NewTarget);\n    } else {\n      result = Super.apply(this, arguments);\n    }\n\n    return (0, _possibleConstructorReturn2.default)(this, result);\n  };\n}\n\nfunction _isNativeReflectConstruct() {\n  if (typeof Reflect === \"undefined\" || !Reflect.construct) return false;\n  if (Reflect.construct.sham) return false;\n  if (typeof Proxy === \"function\") return true;\n\n  try {\n    Date.prototype.toString.call(Reflect.construct(Date, [], function () {}));\n    return true;\n  } catch (e) {\n    return false;\n  }\n}\n\nfunction asyncDecodeAudioData(audioContext, arrayBuffer) {\n  return new Promise(function (resolve, reject) {\n    var promise = audioContext.decodeAudioData(arrayBuffer, resolve, reject); // Newer implementation of \"decodeAudioData\" will return a Promise\n\n    promise && typeof promise.then === 'function' && resolve(promise);\n  });\n}\n\nfunction playDecoded(audioContext, audioBuffer, source) {\n  return new Promise(function (resolve, reject) {\n    var audioContextClosed = new _eventAsPromise.default();\n    var sourceEnded = new _eventAsPromise.default();\n    var unsubscribe = (0, _subscribeEvent.default)(audioContext, 'statechange', function (_ref) {\n      var state = _ref.target.state;\n      return state === 'closed' && audioContextClosed.eventListener();\n    });\n\n    try {\n      source.buffer = audioBuffer; // \"ended\" may not fire if the underlying AudioContext is closed prematurely\n\n      source.onended = sourceEnded.eventListener;\n      source.connect(audioContext.destination);\n      source.start(0);\n      Promise.race([audioContextClosed.upcoming(), sourceEnded.upcoming()]).then(resolve);\n    } catch (err) {\n      reject(err);\n    } finally {\n      unsubscribe();\n    }\n  });\n}\n\nvar SpeechSynthesisUtterance = /*#__PURE__*/function (_EventTarget) {\n  (0, _inherits2.default)(SpeechSynthesisUtterance, _EventTarget);\n\n  var _super = _createSuper(SpeechSynthesisUtterance);\n\n  function SpeechSynthesisUtterance(text) {\n    var _this;\n\n    (0, _classCallCheck2.default)(this, SpeechSynthesisUtterance);\n    _this = _super.call(this);\n    _this._lang = null;\n    _this._pitch = 1;\n    _this._rate = 1;\n    _this._voice = null;\n    _this._volume = 1;\n    _this.text = text;\n    _this.onboundary = null;\n    _this.onend = null;\n    _this.onerror = null;\n    _this.onmark = null;\n    _this.onpause = null;\n    _this.onresume = null;\n    _this.onstart = null;\n    return _this;\n  }\n\n  (0, _createClass2.default)(SpeechSynthesisUtterance, [{\n    key: \"preload\",\n    value: function preload(_ref2) {\n      var deploymentId = _ref2.deploymentId,\n          fetchCredentials = _ref2.fetchCredentials,\n          outputFormat = _ref2.outputFormat;\n      this.arrayBufferPromise = (0, _fetchSpeechData.default)({\n        fetchCredentials: fetchCredentials,\n        deploymentId: deploymentId,\n        lang: this.lang || window.navigator.language,\n        outputFormat: outputFormat,\n        pitch: this.pitch,\n        rate: this.rate,\n        text: this.text,\n        voice: this.voice && this.voice.voiceURI,\n        volume: this.volume\n      }); // We need to call \"catch\" to make sure the Promise is running.\n      // We will ignore the reject result and handled in play() later.\n\n      this.arrayBufferPromise.catch();\n    }\n  }, {\n    key: \"play\",\n    value: function () {\n      var _play = (0, _asyncToGenerator2.default)( /*#__PURE__*/_regenerator.default.mark(function _callee(audioContext) {\n        var source, audioBuffer;\n        return _regenerator.default.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                _context.prev = 0; // We should emit \"start\" event even if preload() failed.\n\n                this.dispatchEvent(new _SpeechSynthesisEvent.default('start')); // HACK: iOS requires bufferSourceNode to be constructed before decoding data.\n\n                source = audioContext.createBufferSource();\n                _context.t0 = asyncDecodeAudioData;\n                _context.t1 = audioContext;\n                _context.next = 7;\n                return this.arrayBufferPromise;\n\n              case 7:\n                _context.t2 = _context.sent;\n                _context.next = 10;\n                return (0, _context.t0)(_context.t1, _context.t2);\n\n              case 10:\n                audioBuffer = _context.sent;\n                this._playingSource = source;\n                _context.next = 14;\n                return playDecoded(audioContext, audioBuffer, source);\n\n              case 14:\n                this._playingSource = null;\n                this.dispatchEvent(new _SpeechSynthesisEvent.default('end'));\n                _context.next = 21;\n                break;\n\n              case 18:\n                _context.prev = 18;\n                _context.t3 = _context[\"catch\"](0); // \"message\" is not in spec but to provide a friendly message.\n\n                this.dispatchEvent(new ErrorEvent('error', {\n                  error: 'synthesis-failed',\n                  message: _context.t3.stack\n                }));\n\n              case 21:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, this, [[0, 18]]);\n      }));\n\n      function play(_x) {\n        return _play.apply(this, arguments);\n      }\n\n      return play;\n    }()\n  }, {\n    key: \"stop\",\n    value: function stop() {\n      this._playingSource && this._playingSource.stop();\n    }\n  }, {\n    key: \"lang\",\n    get: function get() {\n      return this._lang;\n    },\n    set: function set(value) {\n      this._lang = value;\n    }\n  }, {\n    key: \"pitch\",\n    get: function get() {\n      return this._pitch;\n    },\n    set: function set(value) {\n      this._pitch = value;\n    }\n  }, {\n    key: \"rate\",\n    get: function get() {\n      return this._rate;\n    },\n    set: function set(value) {\n      this._rate = value;\n    }\n  }, {\n    key: \"voice\",\n    get: function get() {\n      return this._voice;\n    },\n    set: function set(value) {\n      this._voice = value;\n    }\n  }, {\n    key: \"volume\",\n    get: function get() {\n      return this._volume;\n    },\n    set: function set(value) {\n      this._volume = value;\n    }\n  }]);\n  return SpeechSynthesisUtterance;\n}(_eventTargetShimEs.EventTarget);\n\n(0, _eventTargetShimEs.defineEventAttribute)(SpeechSynthesisUtterance.prototype, 'boundary');\n(0, _eventTargetShimEs.defineEventAttribute)(SpeechSynthesisUtterance.prototype, 'end');\n(0, _eventTargetShimEs.defineEventAttribute)(SpeechSynthesisUtterance.prototype, 'error');\n(0, _eventTargetShimEs.defineEventAttribute)(SpeechSynthesisUtterance.prototype, 'mark');\n(0, _eventTargetShimEs.defineEventAttribute)(SpeechSynthesisUtterance.prototype, 'pause');\n(0, _eventTargetShimEs.defineEventAttribute)(SpeechSynthesisUtterance.prototype, 'resume');\n(0, _eventTargetShimEs.defineEventAttribute)(SpeechSynthesisUtterance.prototype, 'start');\nvar _default = SpeechSynthesisUtterance;\nexports.default = _default;","map":{"version":3,"sources":["../../../src/SpeechServices/TextToSpeech/SpeechSynthesisUtterance.js"],"names":["promise","audioContext","resolve","audioContextClosed","EventAsPromise","sourceEnded","unsubscribe","state","source","Promise","reject","SpeechSynthesisUtterance","EventTarget","value","deploymentId","fetchCredentials","outputFormat","lang","window","pitch","rate","text","voice","volume","SpeechSynthesisEvent","audioBuffer","asyncDecodeAudioData","arrayBufferPromise","playDecoded","error","message","stack"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;AAEA,IAAA,kBAAA,GAAA,OAAA,CAAA,uBAAA,CAAA;;AACA,IAAA,eAAA,GAAA,sBAAA,CAAA,OAAA,CAAA,kBAAA,CAAA,CAAA;;AAEA,IAAA,gBAAA,GAAA,sBAAA,CAAA,OAAA,CAAA,mBAAA,CAAA,CAAA;;AACA,IAAA,qBAAA,GAAA,sBAAA,CAAA,OAAA,CAAA,wBAAA,CAAA,CAAA;;AACA,IAAA,eAAA,GAAA,sBAAA,CAAA,OAAA,CAAA,kBAAA,CAAA,CAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAEA,SAAA,oBAAA,CAAA,YAAA,EAAA,WAAA,EAAyD;AACvD,SAAO,IAAA,OAAA,CAAY,UAAA,OAAA,EAAA,MAAA,EAAqB;AACtC,QAAMA,OAAO,GAAGC,YAAY,CAAZA,eAAAA,CAAAA,WAAAA,EAAAA,OAAAA,EADsB,MACtBA,CAAhB,CADsC,CAGtC;;AACAD,IAAAA,OAAO,IAAI,OAAOA,OAAO,CAAd,IAAA,KAAXA,UAAAA,IAAiDE,OAAO,CAAxDF,OAAwD,CAAxDA;AAJF,GAAO,CAAP;AAMD;;AAED,SAAA,WAAA,CAAA,YAAA,EAAA,WAAA,EAAA,MAAA,EAAwD;AACtD,SAAO,IAAA,OAAA,CAAY,UAAA,OAAA,EAAA,MAAA,EAAqB;AACtC,QAAMG,kBAAkB,GAAG,IAAIC,eAAAA,CAA/B,OAA2B,EAA3B;AACA,QAAMC,WAAW,GAAG,IAAID,eAAAA,CAAxB,OAAoB,EAApB;AACA,QAAME,WAAW,GAAG,CAAA,GAAA,eAAA,CAAA,OAAA,EAAA,YAAA,EAAA,aAAA,EAGlB,UAAA,IAAA,EAAA;AAAA,UAAaC,KAAb,GAAA,IAAA,CAAA,MAAA,CAAA,KAAA;AAAA,aAA2BA,KAAK,KAALA,QAAAA,IAAsBJ,kBAAkB,CAAnE,aAAiDA,EAAjD;AAHF,KAAoB,CAApB;;AAMA,QAAI;AACFK,MAAAA,MAAM,CAANA,MAAAA,GADE,WACFA,CADE,CAEF;;AACAA,MAAAA,MAAM,CAANA,OAAAA,GAAiBH,WAAW,CAA5BG,aAAAA;AAEAA,MAAAA,MAAM,CAANA,OAAAA,CAAeP,YAAY,CAA3BO,WAAAA;AACAA,MAAAA,MAAM,CAANA,KAAAA,CAAAA,CAAAA;AAEAC,MAAAA,OAAO,CAAPA,IAAAA,CAAa,CAACN,kBAAkB,CAAnB,QAACA,EAAD,EAAgCE,WAAW,CAAxDI,QAA6CJ,EAAhC,CAAbI,EAAAA,IAAAA,CAAAA,OAAAA;AARF,KAAA,CASE,OAAA,GAAA,EAAY;AACZC,MAAAA,MAAM,CAANA,GAAM,CAANA;AAVF,KAAA,SAWU;AACRJ,MAAAA,WAAW;AACZ;AAtBH,GAAO,CAAP;AAwBD;;IAEKK,wB;;;;;AACJ,WAAA,wBAAA,CAAA,IAAA,EAAkB;AAAA,QAAA,KAAA;;AAAA,KAAA,GAAA,gBAAA,CAAA,OAAA,EAAA,IAAA,EAAA,wBAAA;AAChB,IAAA,KAAA,GAAA,MAAA,CAAA,IAAA,CAAA,IAAA,CAAA;AAEA,IAAA,KAAA,CAAA,KAAA,GAAA,IAAA;AACA,IAAA,KAAA,CAAA,MAAA,GAAA,CAAA;AACA,IAAA,KAAA,CAAA,KAAA,GAAA,CAAA;AACA,IAAA,KAAA,CAAA,MAAA,GAAA,IAAA;AACA,IAAA,KAAA,CAAA,OAAA,GAAA,CAAA;AAEA,IAAA,KAAA,CAAA,IAAA,GAAA,IAAA;AAEA,IAAA,KAAA,CAAA,UAAA,GAAA,IAAA;AACA,IAAA,KAAA,CAAA,KAAA,GAAA,IAAA;AACA,IAAA,KAAA,CAAA,OAAA,GAAA,IAAA;AACA,IAAA,KAAA,CAAA,MAAA,GAAA,IAAA;AACA,IAAA,KAAA,CAAA,OAAA,GAAA,IAAA;AACA,IAAA,KAAA,CAAA,QAAA,GAAA,IAAA;AACA,IAAA,KAAA,CAAA,OAAA,GAAA,IAAA;AAjBgB,WAAA,KAAA;AAkBjB;;;;mCA8CE;AAAA,UAHDG,YAGC,GAAA,KAAA,CAHDA,YAGC;AAAA,UAFDC,gBAEC,GAAA,KAAA,CAFDA,gBAEC;AAAA,UADDC,YACC,GAAA,KAAA,CADDA,YACC;AACD,WAAA,kBAAA,GAA0B,CAAA,GAAA,gBAAA,CAAA,OAAA,EAAgB;AACxCD,QAAAA,gBAAgB,EADwB,gBAAA;AAExCD,QAAAA,YAAY,EAF4B,YAAA;AAGxCG,QAAAA,IAAI,EAAE,KAAA,IAAA,IAAaC,MAAM,CAANA,SAAAA,CAHqB,QAAA;AAIxCF,QAAAA,YAAY,EAJ4B,YAAA;AAKxCG,QAAAA,KAAK,EAAE,KALiC,KAAA;AAMxCC,QAAAA,IAAI,EAAE,KANkC,IAAA;AAOxCC,QAAAA,IAAI,EAAE,KAPkC,IAAA;AAQxCC,QAAAA,KAAK,EAAE,KAAA,KAAA,IAAc,KAAA,KAAA,CARmB,QAAA;AASxCC,QAAAA,MAAM,EAAE,KAAKA;AAT2B,OAAhB,CAA1B,CADC,CAaD;AACA;;AACA,WAAA,kBAAA,CAAA,KAAA;AACD;;;;2GAEUtB,Y;;;;;;mCAEP;;AACA,qBAAA,aAAA,CAAmB,IAAIuB,qBAAAA,CAAJ,OAAA,CAAnB,OAAmB,CAAnB,E,CAEA;;AACMhB,gBAAAA,M,GAASP,YAAY,CAAZA,kBAAAA,EAATO;8BACoBkB,oB;8BAAqBzB,Y;;uBAAoB,KAAK0B,kB;;;;;;;;AAAlEF,gBAAAA,W,gBAAAA;AAEN,qBAAA,cAAA,GAAA,MAAA;;uBAEMG,WAAW,CAAA,YAAA,EAAA,WAAA,EAAA,MAAA,C;;;AAEjB,qBAAA,cAAA,GAAA,IAAA;AACA,qBAAA,aAAA,CAAmB,IAAIJ,qBAAAA,CAAJ,OAAA,CAAnB,KAAmB,CAAnB;;;;;;oDAEA;;AACA,qBAAA,aAAA,CAAmB,IAAA,UAAA,CAAA,OAAA,EAAwB;AAAEK,kBAAAA,KAAK,EAAP,kBAAA;AAA6BC,kBAAAA,OAAO,EAAE,QAAA,CAAA,EAAA,CAAMC;AAA5C,iBAAxB,CAAnB;;;;;;;;;;;;;;;;;;2BAIG;AACL,WAAA,cAAA,IAAuB,KAAA,cAAA,CAAvB,IAAuB,EAAvB;AACD;;;wBArFU;AACT,aAAO,KAAP,KAAA;;sBAGOlB,K,EAAO;AACd,WAAA,KAAA,GAAA,KAAA;AACD;;;wBAEW;AACV,aAAO,KAAP,MAAA;;sBAGQA,K,EAAO;AACf,WAAA,MAAA,GAAA,KAAA;AACD;;;wBAEU;AACT,aAAO,KAAP,KAAA;;sBAGOA,K,EAAO;AACd,WAAA,KAAA,GAAA,KAAA;AACD;;;wBAEW;AACV,aAAO,KAAP,MAAA;;sBAGQA,K,EAAO;AACf,WAAA,MAAA,GAAA,KAAA;AACD;;;wBAEY;AACX,aAAO,KAAP,OAAA;;sBAGSA,K,EAAO;AAChB,WAAA,OAAA,GAAA,KAAA;AACD;;;EA3DoCD,kBAAAA,CAAAA,W;;AA6GvC,CAAA,GAAA,kBAAA,CAAA,oBAAA,EAAqBD,wBAAwB,CAA7C,SAAA,EAAA,UAAA;AACA,CAAA,GAAA,kBAAA,CAAA,oBAAA,EAAqBA,wBAAwB,CAA7C,SAAA,EAAA,KAAA;AACA,CAAA,GAAA,kBAAA,CAAA,oBAAA,EAAqBA,wBAAwB,CAA7C,SAAA,EAAA,OAAA;AACA,CAAA,GAAA,kBAAA,CAAA,oBAAA,EAAqBA,wBAAwB,CAA7C,SAAA,EAAA,MAAA;AACA,CAAA,GAAA,kBAAA,CAAA,oBAAA,EAAqBA,wBAAwB,CAA7C,SAAA,EAAA,OAAA;AACA,CAAA,GAAA,kBAAA,CAAA,oBAAA,EAAqBA,wBAAwB,CAA7C,SAAA,EAAA,QAAA;AACA,CAAA,GAAA,kBAAA,CAAA,oBAAA,EAAqBA,wBAAwB,CAA7C,SAAA,EAAA,OAAA;eAEeA,wB","sourcesContent":["/* eslint no-empty: [\"error\", { \"allowEmptyCatch\": true }] */\n\nimport { defineEventAttribute, EventTarget } from 'event-target-shim-es5';\nimport EventAsPromise from 'event-as-promise';\n\nimport fetchSpeechData from './fetchSpeechData';\nimport SpeechSynthesisEvent from './SpeechSynthesisEvent';\nimport subscribeEvent from './subscribeEvent';\n\nfunction asyncDecodeAudioData(audioContext, arrayBuffer) {\n  return new Promise((resolve, reject) => {\n    const promise = audioContext.decodeAudioData(arrayBuffer, resolve, reject);\n\n    // Newer implementation of \"decodeAudioData\" will return a Promise\n    promise && typeof promise.then === 'function' && resolve(promise);\n  });\n}\n\nfunction playDecoded(audioContext, audioBuffer, source) {\n  return new Promise((resolve, reject) => {\n    const audioContextClosed = new EventAsPromise();\n    const sourceEnded = new EventAsPromise();\n    const unsubscribe = subscribeEvent(\n      audioContext,\n      'statechange',\n      ({ target: { state } }) => state === 'closed' && audioContextClosed.eventListener()\n    );\n\n    try {\n      source.buffer = audioBuffer;\n      // \"ended\" may not fire if the underlying AudioContext is closed prematurely\n      source.onended = sourceEnded.eventListener;\n\n      source.connect(audioContext.destination);\n      source.start(0);\n\n      Promise.race([audioContextClosed.upcoming(), sourceEnded.upcoming()]).then(resolve);\n    } catch (err) {\n      reject(err);\n    } finally {\n      unsubscribe();\n    }\n  });\n}\n\nclass SpeechSynthesisUtterance extends EventTarget {\n  constructor(text) {\n    super();\n\n    this._lang = null;\n    this._pitch = 1;\n    this._rate = 1;\n    this._voice = null;\n    this._volume = 1;\n\n    this.text = text;\n\n    this.onboundary = null;\n    this.onend = null;\n    this.onerror = null;\n    this.onmark = null;\n    this.onpause = null;\n    this.onresume = null;\n    this.onstart = null;\n  }\n\n  get lang() {\n    return this._lang;\n  }\n\n  set lang(value) {\n    this._lang = value;\n  }\n\n  get pitch() {\n    return this._pitch;\n  }\n\n  set pitch(value) {\n    this._pitch = value;\n  }\n\n  get rate() {\n    return this._rate;\n  }\n\n  set rate(value) {\n    this._rate = value;\n  }\n\n  get voice() {\n    return this._voice;\n  }\n\n  set voice(value) {\n    this._voice = value;\n  }\n\n  get volume() {\n    return this._volume;\n  }\n\n  set volume(value) {\n    this._volume = value;\n  }\n\n  preload({\n    deploymentId,\n    fetchCredentials,\n    outputFormat\n  }) {\n    this.arrayBufferPromise = fetchSpeechData({\n      fetchCredentials,\n      deploymentId,\n      lang: this.lang || window.navigator.language,\n      outputFormat,\n      pitch: this.pitch,\n      rate: this.rate,\n      text: this.text,\n      voice: this.voice && this.voice.voiceURI,\n      volume: this.volume\n    });\n\n    // We need to call \"catch\" to make sure the Promise is running.\n    // We will ignore the reject result and handled in play() later.\n    this.arrayBufferPromise.catch();\n  }\n\n  async play(audioContext) {\n    try {\n      // We should emit \"start\" event even if preload() failed.\n      this.dispatchEvent(new SpeechSynthesisEvent('start'));\n\n      // HACK: iOS requires bufferSourceNode to be constructed before decoding data.\n      const source = audioContext.createBufferSource();\n      const audioBuffer = await asyncDecodeAudioData(audioContext, await this.arrayBufferPromise);\n\n      this._playingSource = source;\n\n      await playDecoded(audioContext, audioBuffer, source);\n\n      this._playingSource = null;\n      this.dispatchEvent(new SpeechSynthesisEvent('end'));\n    } catch (error) {\n      // \"message\" is not in spec but to provide a friendly message.\n      this.dispatchEvent(new ErrorEvent('error', { error: 'synthesis-failed', message: error.stack }));\n    }\n  }\n\n  stop() {\n    this._playingSource && this._playingSource.stop();\n  }\n}\n\ndefineEventAttribute(SpeechSynthesisUtterance.prototype, 'boundary');\ndefineEventAttribute(SpeechSynthesisUtterance.prototype, 'end');\ndefineEventAttribute(SpeechSynthesisUtterance.prototype, 'error');\ndefineEventAttribute(SpeechSynthesisUtterance.prototype, 'mark');\ndefineEventAttribute(SpeechSynthesisUtterance.prototype, 'pause');\ndefineEventAttribute(SpeechSynthesisUtterance.prototype, 'resume');\ndefineEventAttribute(SpeechSynthesisUtterance.prototype, 'start');\n\nexport default SpeechSynthesisUtterance;\n"]},"metadata":{},"sourceType":"script"}