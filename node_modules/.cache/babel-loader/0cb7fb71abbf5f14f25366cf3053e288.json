{"ast":null,"code":"\"use strict\";\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\");\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\n\nvar _regenerator = _interopRequireDefault(require(\"@babel/runtime/regenerator\"));\n\nvar _asyncToGenerator2 = _interopRequireDefault(require(\"@babel/runtime/helpers/asyncToGenerator\"));\n\nvar _classCallCheck2 = _interopRequireDefault(require(\"@babel/runtime/helpers/classCallCheck\"));\n\nvar _createClass2 = _interopRequireDefault(require(\"@babel/runtime/helpers/createClass\"));\n\nvar _memoizeOne = _interopRequireDefault(require(\"memoize-one\"));\n\nvar _AudioContextConsumer = _interopRequireDefault(require(\"./AudioContextConsumer\"));\n/* eslint no-await-in-loop: \"off\" */\n\n\nvar _default = /*#__PURE__*/function () {\n  function _default(_ref) {\n    var audioContext = _ref.audioContext,\n        ponyfill = _ref.ponyfill;\n    (0, _classCallCheck2.default)(this, _default);\n    this.consumer = null;\n    this.paused = false;\n    this.queue = [];\n    this.getAudioContext = (0, _memoizeOne.default)(function () {\n      return audioContext || new ponyfill.AudioContext();\n    });\n  }\n\n  (0, _createClass2.default)(_default, [{\n    key: \"pause\",\n    value: function pause() {\n      this.paused = true;\n      this.consumer && this.consumer.pause();\n    }\n  }, {\n    key: \"push\",\n    value: function push(utterance) {\n      this.queue.push(utterance);\n      this.startConsumer();\n    }\n  }, {\n    key: \"resume\",\n    value: function resume() {\n      this.paused = false;\n\n      if (this.consumer) {\n        this.consumer.resume();\n      } else {\n        this.startConsumer();\n      }\n    }\n  }, {\n    key: \"startConsumer\",\n    value: function () {\n      var _startConsumer = (0, _asyncToGenerator2.default)( /*#__PURE__*/_regenerator.default.mark(function _callee() {\n        return _regenerator.default.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                if (!(!this.paused && this.queue.length && !this.consumer)) {\n                  _context.next = 7;\n                  break;\n                }\n\n                this.consumer = new _AudioContextConsumer.default(this.getAudioContext());\n                _context.next = 4;\n                return this.consumer.start(this.queue);\n\n              case 4:\n                this.consumer = null;\n                _context.next = 0;\n                break;\n\n              case 7:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, this);\n      }));\n\n      function startConsumer() {\n        return _startConsumer.apply(this, arguments);\n      }\n\n      return startConsumer;\n    }()\n  }, {\n    key: \"stop\",\n    value: function stop() {\n      this.queue.splice(0);\n      this.consumer && this.consumer.stop();\n    }\n  }, {\n    key: \"speaking\",\n    get: function get() {\n      return !!this.consumer;\n    }\n  }]);\n  return _default;\n}();\n\nexports.default = _default;","map":{"version":3,"sources":["../../../src/SpeechServices/TextToSpeech/AudioContextQueue.js"],"names":["audioContext","ponyfill","utterance","consumer","AudioContextConsumer"],"mappings":";;;;;;;;;;;;;;;;;AAEA,IAAA,WAAA,GAAA,sBAAA,CAAA,OAAA,CAAA,aAAA,CAAA,CAAA;;AAEA,IAAA,qBAAA,GAAA,sBAAA,CAAA,OAAA,CAAA,wBAAA,CAAA,CAAA;AAJA;;;;AAOE,WAAA,QAAA,CAAA,IAAA,EAAwC;AAAA,QAA1BA,YAA0B,GAAA,IAAA,CAA1BA,YAA0B;AAAA,QAAZC,QAAY,GAAA,IAAA,CAAZA,QAAY;AAAA,KAAA,GAAA,gBAAA,CAAA,OAAA,EAAA,IAAA,EAAA,QAAA;AACtC,SAAA,QAAA,GAAA,IAAA;AACA,SAAA,MAAA,GAAA,KAAA;AACA,SAAA,KAAA,GAAA,EAAA;AAEA,SAAA,eAAA,GAAuB,CAAA,GAAA,WAAA,CAAA,OAAA,EAAQ,YAAA;AAAA,aAAMD,YAAY,IAAI,IAAIC,QAAQ,CAAlC,YAAsB,EAAtB;AAA/B,KAAuB,CAAvB;AACD;;;;4BAEO;AACN,WAAA,MAAA,GAAA,IAAA;AACA,WAAA,QAAA,IAAiB,KAAA,QAAA,CAAjB,KAAiB,EAAjB;AACD;;;yBAEIC,S,EAAW;AACd,WAAA,KAAA,CAAA,IAAA,CAAA,SAAA;AACA,WAAA,aAAA;AACD;;;6BAEQ;AACP,WAAA,MAAA,GAAA,KAAA;;AAEA,UAAI,KAAJ,QAAA,EAAmB;AACjB,aAAA,QAAA,CAAA,MAAA;AADF,OAAA,MAEO;AACL,aAAA,aAAA;AACD;AACF;;;;;;;;;sBAOQ,CAAC,KAAD,MAAA,IAAgB,KAAA,KAAA,CAAhB,MAAA,IAAqC,CAAC,KAAKC,Q;;;;;AAChD,qBAAA,QAAA,GAAgB,IAAIC,qBAAAA,CAAJ,OAAA,CAAyB,KAAzC,eAAyC,EAAzB,CAAhB;;uBAEM,KAAA,QAAA,CAAA,KAAA,CAAoB,KAApB,KAAA,C;;;AAEN,qBAAA,QAAA,GAAA,IAAA;;;;;;;;;;;;;;;;;;;;2BAIG;AACL,WAAA,KAAA,CAAA,MAAA,CAAA,CAAA;AACA,WAAA,QAAA,IAAiB,KAAA,QAAA,CAAjB,IAAiB,EAAjB;AACD;;;wBAjBc;AACb,aAAO,CAAC,CAAC,KAAT,QAAA;AACD","sourcesContent":["/* eslint no-await-in-loop: \"off\" */\n\nimport memoize from 'memoize-one';\n\nimport AudioContextConsumer from './AudioContextConsumer';\n\nexport default class {\n  constructor({ audioContext, ponyfill }) {\n    this.consumer = null;\n    this.paused = false;\n    this.queue = [];\n\n    this.getAudioContext = memoize(() => audioContext || new ponyfill.AudioContext());\n  }\n\n  pause() {\n    this.paused = true;\n    this.consumer && this.consumer.pause();\n  }\n\n  push(utterance) {\n    this.queue.push(utterance);\n    this.startConsumer();\n  }\n\n  resume() {\n    this.paused = false;\n\n    if (this.consumer) {\n      this.consumer.resume();\n    } else {\n      this.startConsumer();\n    }\n  }\n\n  get speaking() {\n    return !!this.consumer;\n  }\n\n  async startConsumer() {\n    while (!this.paused && this.queue.length && !this.consumer) {\n      this.consumer = new AudioContextConsumer(this.getAudioContext());\n\n      await this.consumer.start(this.queue);\n\n      this.consumer = null;\n    }\n  }\n\n  stop() {\n    this.queue.splice(0);\n    this.consumer && this.consumer.stop();\n  }\n}\n"]},"metadata":{},"sourceType":"script"}