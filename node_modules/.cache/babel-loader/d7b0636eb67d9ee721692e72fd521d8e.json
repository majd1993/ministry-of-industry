{"ast":null,"code":"\"use strict\"; // Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n/**\n * Represents the JSON used in the synthesis.context message sent to the speech service.\n * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.\n */\n\nvar SynthesisContext =\n/** @class */\nfunction () {\n  function SynthesisContext(speechSynthesizer) {\n    this.privContext = {};\n    this.privSpeechSynthesizer = speechSynthesizer;\n  }\n  /**\n   * Adds a section to the synthesis.context object.\n   * @param sectionName Name of the section to add.\n   * @param value JSON serializable object that represents the value.\n   */\n\n\n  SynthesisContext.prototype.setSection = function (sectionName, value) {\n    this.privContext[sectionName] = value;\n  };\n\n  Object.defineProperty(SynthesisContext.prototype, \"audioOutputFormat\", {\n    /**\n     * Sets the audio output format for synthesis context generation.\n     * @param format {AudioOutputFormatImpl} the output format\n     */\n    set: function set(format) {\n      this.privAudioOutputFormat = format;\n    },\n    enumerable: true,\n    configurable: true\n  });\n\n  SynthesisContext.prototype.toJSON = function () {\n    var synthesisSection = this.buildSynthesisContext();\n    this.setSection(\"synthesis\", synthesisSection);\n    return JSON.stringify(this.privContext);\n  };\n\n  SynthesisContext.prototype.buildSynthesisContext = function () {\n    return {\n      audio: {\n        metadataOptions: {\n          sentenceBoundaryEnabled: false,\n          wordBoundaryEnabled: !!this.privSpeechSynthesizer.wordBoundary\n        },\n        outputFormat: this.privAudioOutputFormat.requestAudioFormatString\n      },\n      language: {\n        autoDetection: this.privSpeechSynthesizer.autoDetectSourceLanguage\n      }\n    };\n  };\n\n  return SynthesisContext;\n}();\n\nexports.SynthesisContext = SynthesisContext;","map":{"version":3,"sources":["src/common.speech/SynthesisContext.ts"],"names":[],"mappings":"cAAA;AACA;;;;;AAKA;;;AAGG;;AACH,IAAA,gBAAA;AAAA;AAAA,YAAA;AAKI,WAAA,gBAAA,CAAY,iBAAZ,EAAgD;AAJxC,SAAA,WAAA,GAA0C,EAA1C;AAKJ,SAAK,qBAAL,GAA6B,iBAA7B;AACH;AAED;;;;AAIG;;;AACI,EAAA,gBAAA,CAAA,SAAA,CAAA,UAAA,GAAP,UAAkB,WAAlB,EAAuC,KAAvC,EAAiD;AAC7C,SAAK,WAAL,CAAiB,WAAjB,IAAgC,KAAhC;AACH,GAFM;;AAQP,EAAA,MAAA,CAAA,cAAA,CAAW,gBAAA,CAAA,SAAX,EAAW,mBAAX,EAA4B;AAJ5B;;;AAGG;SACH,aAA6B,MAA7B,EAA0D;AACtD,WAAK,qBAAL,GAA6B,MAA7B;AACH,KAF2B;oBAAA;;AAAA,GAA5B;;AAIO,EAAA,gBAAA,CAAA,SAAA,CAAA,MAAA,GAAP,YAAA;AAEI,QAAM,gBAAgB,GAAsB,KAAK,qBAAL,EAA5C;AACA,SAAK,UAAL,CAAgB,WAAhB,EAA6B,gBAA7B;AAEA,WAAO,IAAI,CAAC,SAAL,CAAe,KAAK,WAApB,CAAP;AACH,GANM;;AAQC,EAAA,gBAAA,CAAA,SAAA,CAAA,qBAAA,GAAR,YAAA;AACI,WAAO;AACH,MAAA,KAAK,EAAE;AACH,QAAA,eAAe,EAAE;AACb,UAAA,uBAAuB,EAAE,KADZ;AAEb,UAAA,mBAAmB,EAAG,CAAC,CAAC,KAAK,qBAAL,CAA2B;AAFtC,SADd;AAKH,QAAA,YAAY,EAAE,KAAK,qBAAL,CAA2B;AALtC,OADJ;AAQH,MAAA,QAAQ,EAAE;AACN,QAAA,aAAa,EAAE,KAAK,qBAAL,CAA2B;AADpC;AARP,KAAP;AAYH,GAbO;;AAcZ,SAAA,gBAAA;AAAC,CAhDD,EAAA;;AAAa,OAAA,CAAA,gBAAA,GAAA,gBAAA","sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT license.\r\n\r\nimport { AudioOutputFormatImpl } from \"../sdk/Audio/AudioOutputFormat\";\r\nimport { PropertyId, SpeechSynthesizer } from \"../sdk/Exports\";\r\n\r\n/**\r\n * Represents the JSON used in the synthesis.context message sent to the speech service.\r\n * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.\r\n */\r\nexport class SynthesisContext {\r\n    private privContext: { [section: string]: any } = {};\r\n    private privSpeechSynthesizer: SpeechSynthesizer;\r\n    private privAudioOutputFormat: AudioOutputFormatImpl;\r\n\r\n    constructor(speechSynthesizer: SpeechSynthesizer) {\r\n        this.privSpeechSynthesizer = speechSynthesizer;\r\n    }\r\n\r\n    /**\r\n     * Adds a section to the synthesis.context object.\r\n     * @param sectionName Name of the section to add.\r\n     * @param value JSON serializable object that represents the value.\r\n     */\r\n    public setSection(sectionName: string, value: any): void {\r\n        this.privContext[sectionName] = value;\r\n    }\r\n\r\n    /**\r\n     * Sets the audio output format for synthesis context generation.\r\n     * @param format {AudioOutputFormatImpl} the output format\r\n     */\r\n    public set audioOutputFormat(format: AudioOutputFormatImpl) {\r\n        this.privAudioOutputFormat = format;\r\n    }\r\n\r\n    public toJSON(): string {\r\n\r\n        const synthesisSection: ISynthesisSection = this.buildSynthesisContext();\r\n        this.setSection(\"synthesis\", synthesisSection);\r\n\r\n        return JSON.stringify(this.privContext);\r\n    }\r\n\r\n    private buildSynthesisContext(): ISynthesisSection {\r\n        return {\r\n            audio: {\r\n                metadataOptions: {\r\n                    sentenceBoundaryEnabled: false,\r\n                    wordBoundaryEnabled: (!!this.privSpeechSynthesizer.wordBoundary),\r\n                },\r\n                outputFormat: this.privAudioOutputFormat.requestAudioFormatString,\r\n            },\r\n            language: {\r\n                autoDetection: this.privSpeechSynthesizer.autoDetectSourceLanguage\r\n            }\r\n        };\r\n    }\r\n}\r\n\r\ninterface ISynthesisSection {\r\n    audio: {\r\n        outputFormat: string,\r\n        metadataOptions: {\r\n            wordBoundaryEnabled: boolean,\r\n            sentenceBoundaryEnabled: boolean,\r\n        }\r\n    };\r\n    language: {\r\n        autoDetection: boolean\r\n    };\r\n}\r\n"]},"metadata":{},"sourceType":"script"}