{"ast":null,"code":"import _classCallCheck from \"/home/Ubility/Desktop/ministry-of-industry-and-advanced-technology/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\nimport _createClass from \"/home/Ubility/Desktop/ministry-of-industry-and-advanced-technology/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass\";\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Represents the JSON used in the synthesis.context message sent to the speech service.\n * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.\n */\nexport var SynthesisContext = /*#__PURE__*/function () {\n  function SynthesisContext(speechSynthesizer) {\n    _classCallCheck(this, SynthesisContext);\n\n    this.privContext = {};\n    this.privSpeechSynthesizer = speechSynthesizer;\n  }\n  /**\n   * Adds a section to the synthesis.context object.\n   * @param sectionName Name of the section to add.\n   * @param value JSON serializable object that represents the value.\n   */\n\n\n  _createClass(SynthesisContext, [{\n    key: \"setSection\",\n    value: function setSection(sectionName, value) {\n      this.privContext[sectionName] = value;\n    }\n    /**\n     * Sets the audio output format for synthesis context generation.\n     * @param format {AudioOutputFormatImpl} the output format\n     */\n\n  }, {\n    key: \"audioOutputFormat\",\n    set: function set(format) {\n      this.privAudioOutputFormat = format;\n    }\n  }, {\n    key: \"toJSON\",\n    value: function toJSON() {\n      var synthesisSection = this.buildSynthesisContext();\n      this.setSection(\"synthesis\", synthesisSection);\n      return JSON.stringify(this.privContext);\n    }\n  }, {\n    key: \"buildSynthesisContext\",\n    value: function buildSynthesisContext() {\n      return {\n        audio: {\n          metadataOptions: {\n            sentenceBoundaryEnabled: false,\n            wordBoundaryEnabled: !!this.privSpeechSynthesizer.wordBoundary\n          },\n          outputFormat: this.privAudioOutputFormat.requestAudioFormatString\n        },\n        language: {\n          autoDetection: this.privSpeechSynthesizer.autoDetectSourceLanguage\n        }\n      };\n    }\n  }]);\n\n  return SynthesisContext;\n}();","map":{"version":3,"sources":["src/common.speech/SynthesisContext.ts"],"names":[],"mappings":";;AAAA;AACA;;AAKA;;;AAGG;AACH,WAAa,gBAAb;AAKI,4BAAY,iBAAZ,EAAgD;AAAA;;AAJxC,SAAA,WAAA,GAA0C,EAA1C;AAKJ,SAAK,qBAAL,GAA6B,iBAA7B;AACH;AAED;;;;AAIG;;;AAbP;AAAA;AAAA,WAcW,oBAAW,WAAX,EAAgC,KAAhC,EAA0C;AAC7C,WAAK,WAAL,CAAiB,WAAjB,IAAgC,KAAhC;AACH;AAED;;;AAGG;;AArBP;AAAA;AAAA,SAsBI,aAA6B,MAA7B,EAA0D;AACtD,WAAK,qBAAL,GAA6B,MAA7B;AACH;AAxBL;AAAA;AAAA,WA0BW,kBAAM;AAET,UAAM,gBAAgB,GAAsB,KAAK,qBAAL,EAA5C;AACA,WAAK,UAAL,CAAgB,WAAhB,EAA6B,gBAA7B;AAEA,aAAO,IAAI,CAAC,SAAL,CAAe,KAAK,WAApB,CAAP;AACH;AAhCL;AAAA;AAAA,WAkCY,iCAAqB;AACzB,aAAO;AACH,QAAA,KAAK,EAAE;AACH,UAAA,eAAe,EAAE;AACb,YAAA,uBAAuB,EAAE,KADZ;AAEb,YAAA,mBAAmB,EAAG,CAAC,CAAC,KAAK,qBAAL,CAA2B;AAFtC,WADd;AAKH,UAAA,YAAY,EAAE,KAAK,qBAAL,CAA2B;AALtC,SADJ;AAQH,QAAA,QAAQ,EAAE;AACN,UAAA,aAAa,EAAE,KAAK,qBAAL,CAA2B;AADpC;AARP,OAAP;AAYH;AA/CL;;AAAA;AAAA","sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT license.\r\n\r\nimport { AudioOutputFormatImpl } from \"../sdk/Audio/AudioOutputFormat\";\r\nimport { PropertyId, SpeechSynthesizer } from \"../sdk/Exports\";\r\n\r\n/**\r\n * Represents the JSON used in the synthesis.context message sent to the speech service.\r\n * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.\r\n */\r\nexport class SynthesisContext {\r\n    private privContext: { [section: string]: any } = {};\r\n    private privSpeechSynthesizer: SpeechSynthesizer;\r\n    private privAudioOutputFormat: AudioOutputFormatImpl;\r\n\r\n    constructor(speechSynthesizer: SpeechSynthesizer) {\r\n        this.privSpeechSynthesizer = speechSynthesizer;\r\n    }\r\n\r\n    /**\r\n     * Adds a section to the synthesis.context object.\r\n     * @param sectionName Name of the section to add.\r\n     * @param value JSON serializable object that represents the value.\r\n     */\r\n    public setSection(sectionName: string, value: any): void {\r\n        this.privContext[sectionName] = value;\r\n    }\r\n\r\n    /**\r\n     * Sets the audio output format for synthesis context generation.\r\n     * @param format {AudioOutputFormatImpl} the output format\r\n     */\r\n    public set audioOutputFormat(format: AudioOutputFormatImpl) {\r\n        this.privAudioOutputFormat = format;\r\n    }\r\n\r\n    public toJSON(): string {\r\n\r\n        const synthesisSection: ISynthesisSection = this.buildSynthesisContext();\r\n        this.setSection(\"synthesis\", synthesisSection);\r\n\r\n        return JSON.stringify(this.privContext);\r\n    }\r\n\r\n    private buildSynthesisContext(): ISynthesisSection {\r\n        return {\r\n            audio: {\r\n                metadataOptions: {\r\n                    sentenceBoundaryEnabled: false,\r\n                    wordBoundaryEnabled: (!!this.privSpeechSynthesizer.wordBoundary),\r\n                },\r\n                outputFormat: this.privAudioOutputFormat.requestAudioFormatString,\r\n            },\r\n            language: {\r\n                autoDetection: this.privSpeechSynthesizer.autoDetectSourceLanguage\r\n            }\r\n        };\r\n    }\r\n}\r\n\r\ninterface ISynthesisSection {\r\n    audio: {\r\n        outputFormat: string,\r\n        metadataOptions: {\r\n            wordBoundaryEnabled: boolean,\r\n            sentenceBoundaryEnabled: boolean,\r\n        }\r\n    };\r\n    language: {\r\n        autoDetection: boolean\r\n    };\r\n}\r\n"]},"metadata":{},"sourceType":"module"}