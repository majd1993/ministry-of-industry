{"ast":null,"code":"\"use strict\";\n\nvar _interopRequireWildcard = require(\"@babel/runtime/helpers/interopRequireWildcard\");\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\");\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = _default;\n\nvar _regenerator = _interopRequireDefault(require(\"@babel/runtime/regenerator\"));\n\nvar _asyncToGenerator2 = _interopRequireDefault(require(\"@babel/runtime/helpers/asyncToGenerator\"));\n\nvar _classCallCheck2 = _interopRequireDefault(require(\"@babel/runtime/helpers/classCallCheck\"));\n\nvar _createClass2 = _interopRequireDefault(require(\"@babel/runtime/helpers/createClass\"));\n\nvar _inherits2 = _interopRequireDefault(require(\"@babel/runtime/helpers/inherits\"));\n\nvar _possibleConstructorReturn2 = _interopRequireDefault(require(\"@babel/runtime/helpers/possibleConstructorReturn\"));\n\nvar _getPrototypeOf2 = _interopRequireDefault(require(\"@babel/runtime/helpers/getPrototypeOf\"));\n\nvar _SpeechToText = require(\"web-speech-cognitive-services/lib/SpeechServices/SpeechToText\");\n\nvar _abortControllerEs = _interopRequireDefault(require(\"abort-controller-es5\"));\n\nvar _createCustomEvent = _interopRequireDefault(require(\"./createCustomEvent\"));\n\nvar _createErrorEvent = _interopRequireDefault(require(\"./createErrorEvent\"));\n\nvar _createTaskQueue2 = _interopRequireDefault(require(\"./createTaskQueue\"));\n\nvar _eventTargetShimEs = _interopRequireWildcard(require(\"event-target-shim-es5\"));\n\nvar _playCognitiveServicesStream = _interopRequireDefault(require(\"./playCognitiveServicesStream\"));\n\nvar _playWhiteNoise = _interopRequireDefault(require(\"./playWhiteNoise\"));\n\nvar _SpeechSynthesisAudioStreamUtterance = _interopRequireDefault(require(\"./SpeechSynthesisAudioStreamUtterance\"));\n\nfunction _createSuper(Derived) {\n  var hasNativeReflectConstruct = _isNativeReflectConstruct();\n\n  return function _createSuperInternal() {\n    var Super = (0, _getPrototypeOf2.default)(Derived),\n        result;\n\n    if (hasNativeReflectConstruct) {\n      var NewTarget = (0, _getPrototypeOf2.default)(this).constructor;\n      result = Reflect.construct(Super, arguments, NewTarget);\n    } else {\n      result = Super.apply(this, arguments);\n    }\n\n    return (0, _possibleConstructorReturn2.default)(this, result);\n  };\n}\n\nfunction _isNativeReflectConstruct() {\n  if (typeof Reflect === \"undefined\" || !Reflect.construct) return false;\n  if (Reflect.construct.sham) return false;\n  if (typeof Proxy === \"function\") return true;\n\n  try {\n    Date.prototype.toString.call(Reflect.construct(Date, [], function () {}));\n    return true;\n  } catch (e) {\n    return false;\n  }\n}\n\nfunction _default(_ref) {\n  var audioContext = _ref.audioContext,\n      enableTelemetry = _ref.enableTelemetry,\n      _ref$ponyfill = _ref.ponyfill,\n      ponyfill = _ref$ponyfill === void 0 ? {\n    AudioContext: window.AudioContext || window.webkitAudioContext\n  } : _ref$ponyfill,\n      recognizer = _ref.recognizer,\n      textNormalization = _ref.textNormalization;\n\n  if (!ponyfill.AudioContext) {\n    console.warn('botframework-directlinespeech-sdk: This browser does not support Web Audio API. Speech support is disabled.');\n    return function () {\n      return {};\n    };\n  }\n\n  return function () {\n    var _createSpeechRecognit = (0, _SpeechToText.createSpeechRecognitionPonyfillFromRecognizer)({\n      createRecognizer: function createRecognizer() {\n        return recognizer;\n      },\n      enableTelemetry: enableTelemetry,\n      looseEvents: true,\n      textNormalization: textNormalization\n    }),\n        SpeechGrammarList = _createSpeechRecognit.SpeechGrammarList,\n        SpeechRecognition = _createSpeechRecognit.SpeechRecognition;\n\n    if (!audioContext) {\n      audioContext = new ponyfill.AudioContext();\n    }\n\n    var _createTaskQueue = (0, _createTaskQueue2.default)(),\n        cancelAll = _createTaskQueue.cancelAll,\n        push = _createTaskQueue.push;\n\n    var SpeechSynthesis = /*#__PURE__*/function (_EventTargetShim) {\n      (0, _inherits2.default)(SpeechSynthesis, _EventTargetShim);\n\n      var _super = _createSuper(SpeechSynthesis);\n\n      function SpeechSynthesis() {\n        (0, _classCallCheck2.default)(this, SpeechSynthesis);\n        return _super.apply(this, arguments);\n      }\n\n      (0, _createClass2.default)(SpeechSynthesis, [{\n        key: \"cancel\",\n        value: function cancel() {\n          cancelAll();\n        } // Returns an empty array.\n        // Synthesis is done on the bot side, the content of the voice list is not meaningful on the client side.\n\n      }, {\n        key: \"getVoices\",\n        value: function getVoices() {\n          return [];\n        }\n      }, {\n        key: \"speak\",\n        value: function speak(utterance) {\n          var _push = push(function () {\n            var controller = new _abortControllerEs.default();\n            var signal = controller.signal;\n            return {\n              abort: controller.abort.bind(controller),\n              result: (0, _asyncToGenerator2.default)( /*#__PURE__*/_regenerator.default.mark(function _callee() {\n                return _regenerator.default.wrap(function _callee$(_context) {\n                  while (1) {\n                    switch (_context.prev = _context.next) {\n                      case 0:\n                        utterance.dispatchEvent((0, _createCustomEvent.default)('start'));\n                        _context.prev = 1;\n\n                        if (!utterance.audioStream) {\n                          _context.next = 7;\n                          break;\n                        }\n\n                        _context.next = 5;\n                        return (0, _playCognitiveServicesStream.default)(audioContext, utterance.audioStream, {\n                          signal: signal\n                        });\n\n                      case 5:\n                        _context.next = 9;\n                        break;\n\n                      case 7:\n                        _context.next = 9;\n                        return (0, _playWhiteNoise.default)(audioContext);\n\n                      case 9:\n                        _context.next = 15;\n                        break;\n\n                      case 11:\n                        _context.prev = 11;\n                        _context.t0 = _context[\"catch\"](1);\n\n                        if (!(_context.t0.message !== 'aborted')) {\n                          _context.next = 15;\n                          break;\n                        }\n\n                        return _context.abrupt(\"return\", utterance.dispatchEvent((0, _createErrorEvent.default)(_context.t0)));\n\n                      case 15:\n                        utterance.dispatchEvent((0, _createCustomEvent.default)('end'));\n\n                      case 16:\n                      case \"end\":\n                        return _context.stop();\n                    }\n                  }\n                }, _callee, null, [[1, 11]]);\n              }))()\n            };\n          }),\n              result = _push.result; // Catching the error to prevent uncaught promise error due to cancellation.\n\n\n          result.catch(function (error) {\n            if (!/^cancelled/i.test(error.message)) {\n              throw error;\n            }\n          });\n        }\n      }]);\n      return SpeechSynthesis;\n    }(_eventTargetShimEs.default);\n\n    (0, _eventTargetShimEs.defineEventAttribute)(SpeechSynthesis, 'voiceschanged');\n    return {\n      SpeechGrammarList: SpeechGrammarList,\n      SpeechRecognition: SpeechRecognition,\n      speechSynthesis: new SpeechSynthesis(),\n      SpeechSynthesisUtterance: _SpeechSynthesisAudioStreamUtterance.default\n    };\n  };\n}","map":{"version":3,"sources":["../src/createWebSpeechPonyfillFactory.js"],"names":["audioContext","enableTelemetry","ponyfill","AudioContext","window","webkitAudioContext","recognizer","textNormalization","console","SpeechGrammarList","SpeechRecognition","createRecognizer","looseEvents","cancelAll","push","SpeechSynthesis","EventTargetShim","result","controller","AbortController","signal","abort","utterance","error","speechSynthesis","SpeechSynthesisUtterance","SpeechSynthesisAudioStreamUtterance"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;AAEA,IAAA,aAAA,GAAA,OAAA,CAAA,+DAAA,CAAA;;AAEA,IAAA,kBAAA,GAAA,sBAAA,CAAA,OAAA,CAAA,sBAAA,CAAA,CAAA;;AACA,IAAA,kBAAA,GAAA,sBAAA,CAAA,OAAA,CAAA,qBAAA,CAAA,CAAA;;AACA,IAAA,iBAAA,GAAA,sBAAA,CAAA,OAAA,CAAA,oBAAA,CAAA,CAAA;;AACA,IAAA,iBAAA,GAAA,sBAAA,CAAA,OAAA,CAAA,mBAAA,CAAA,CAAA;;AACA,IAAA,kBAAA,GAAA,uBAAA,CAAA,OAAA,CAAA,uBAAA,CAAA,CAAA;;AACA,IAAA,4BAAA,GAAA,sBAAA,CAAA,OAAA,CAAA,+BAAA,CAAA,CAAA;;AACA,IAAA,eAAA,GAAA,sBAAA,CAAA,OAAA,CAAA,kBAAA,CAAA,CAAA;;AACA,IAAA,oCAAA,GAAA,sBAAA,CAAA,OAAA,CAAA,uCAAA,CAAA,CAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAEe,SAAA,QAAA,CAAA,IAAA,EAQZ;AAAA,MAPDA,YAOC,GAAA,IAAA,CAPDA,YAOC;AAAA,MANDC,eAMC,GAAA,IAAA,CANDA,eAMC;AAAA,MAAA,aAAA,GAAA,IAAA,CALDC,QAKC;AAAA,MALDA,QAKC,GAAA,aAAA,KAAA,KAAA,CAAA,GALU;AACTC,IAAAA,YAAY,EAAEC,MAAM,CAANA,YAAAA,IAAuBA,MAAM,CAACC;AADnC,GAKV,GAAA,aAAA;AAAA,MAFDC,UAEC,GAAA,IAAA,CAFDA,UAEC;AAAA,MADDC,iBACC,GAAA,IAAA,CADDA,iBACC;;AACD,MAAI,CAACL,QAAQ,CAAb,YAAA,EAA4B;AAC1BM,IAAAA,OAAO,CAAPA,IAAAA,CAAAA,6GAAAA;AAIA,WAAO,YAAA;AAAA,aAAA,EAAA;AAAP,KAAA;AACD;;AAED,SAAO,YAAM;AAAA,QAAA,qBAAA,GACsC,CAAA,GAAA,aAAA,CAAA,6CAAA,EAA8C;AAC7FG,MAAAA,gBAAgB,EAAE,SAAA,gBAAA,GAAA;AAAA,eAAA,UAAA;AAD2E,OAAA;AAE7FV,MAAAA,eAAe,EAF8E,eAAA;AAG7FW,MAAAA,WAAW,EAHkF,IAAA;AAI7FL,MAAAA,iBAAiB,EAAjBA;AAJ6F,KAA9C,CADtC;AAAA,QACHE,iBADG,GAAA,qBAAA,CAAA,iBAAA;AAAA,QACgBC,iBADhB,GAAA,qBAAA,CAAA,iBAAA;;AAQX,QAAI,CAAJ,YAAA,EAAmB;AACjBV,MAAAA,YAAY,GAAG,IAAIE,QAAQ,CAA3BF,YAAe,EAAfA;AACD;;AAVU,QAAA,gBAAA,GAYiB,CAAA,GAAA,iBAAA,CAZjB,OAYiB,GAZjB;AAAA,QAYHa,SAZG,GAAA,gBAAA,CAAA,SAAA;AAAA,QAYQC,IAZR,GAAA,gBAAA,CAAA,IAAA;;AAAA,QAcLC,eAdK,GAAA,aAAA,UAAA,gBAAA,EAAA;AAAA,OAAA,GAAA,UAAA,CAAA,OAAA,EAAA,eAAA,EAAA,gBAAA;;AAAA,UAAA,MAAA,GAAA,YAAA,CAAA,eAAA,CAAA;;AAAA,eAAA,eAAA,GAAA;AAAA,SAAA,GAAA,gBAAA,CAAA,OAAA,EAAA,IAAA,EAAA,eAAA;AAAA,eAAA,MAAA,CAAA,KAAA,CAAA,IAAA,EAAA,SAAA,CAAA;AAAA;;AAAA,OAAA,GAAA,aAAA,CAAA,OAAA,EAAA,eAAA,EAAA,CAAA;AAAA,QAAA,GAAA,EAAA,QAAA;AAAA,QAAA,KAAA,EAAA,SAAA,MAAA,GAeA;AACPF,UAAAA,SAAS;AAhBF,SAAA,CAmBT;AACA;;AApBS,OAAA,EAAA;AAAA,QAAA,GAAA,EAAA,WAAA;AAAA,QAAA,KAAA,EAAA,SAAA,SAAA,GAqBG;AACV,iBAAA,EAAA;AACD;AAvBQ,OAAA,EAAA;AAAA,QAAA,GAAA,EAAA,OAAA;AAAA,QAAA,KAAA,EAAA,SAAA,KAAA,CAAA,SAAA,EAyBQ;AAAA,cAAA,KAAA,GACIC,IAAI,CAAC,YAAM;AAC5B,gBAAMI,UAAU,GAAG,IAAIC,kBAAAA,CAAvB,OAAmB,EAAnB;AAD4B,gBAEpBC,MAFoB,GAETF,UAFS,CAAA,MAAA;AAI5B,mBAAO;AACLG,cAAAA,KAAK,EAAEH,UAAU,CAAVA,KAAAA,CAAAA,IAAAA,CADF,UACEA,CADF;AAELD,cAAAA,MAAM,EAAE,CAAA,GAAA,kBAAA,CAAA,OAAA,GAAA,aAAA,YAAA,CAAA,OAAA,CAAA,IAAA,CAAC,SAAA,OAAA,GAAA;AAAA,uBAAA,YAAA,CAAA,OAAA,CAAA,IAAA,CAAA,SAAA,QAAA,CAAA,QAAA,EAAA;AAAA,yBAAA,CAAA,EAAA;AAAA,4BAAA,QAAA,CAAA,IAAA,GAAA,QAAA,CAAA,IAAA;AAAA,2BAAA,CAAA;AACPK,wBAAAA,SAAS,CAATA,aAAAA,CAAwB,CAAA,GAAA,kBAAA,CAAA,OAAA,EAAxBA,OAAwB,CAAxBA;AADO,wBAAA,QAAA,CAAA,IAAA,GAAA,CAAA;;AAAA,4BAAA,CAIDA,SAAS,CAJR,WAAA,EAAA;AAAA,0BAAA,QAAA,CAAA,IAAA,GAAA,CAAA;AAAA;AAAA;;AAAA,wBAAA,QAAA,CAAA,IAAA,GAAA,CAAA;AAAA,+BAKG,CAAA,GAAA,4BAAA,CAAA,OAAA,EAAA,YAAA,EAA0CA,SAAS,CAAnD,WAAA,EAAiE;AAAEF,0BAAAA,MAAM,EAANA;AAAF,yBAAjE,CALH;;AAAA,2BAAA,CAAA;AAAA,wBAAA,QAAA,CAAA,IAAA,GAAA,CAAA;AAAA;;AAAA,2BAAA,CAAA;AAAA,wBAAA,QAAA,CAAA,IAAA,GAAA,CAAA;AAAA,+BAOG,CAAA,GAAA,eAAA,CAAA,OAAA,EAPH,YAOG,CAPH;;AAAA,2BAAA,CAAA;AAAA,wBAAA,QAAA,CAAA,IAAA,GAAA,EAAA;AAAA;;AAAA,2BAAA,EAAA;AAAA,wBAAA,QAAA,CAAA,IAAA,GAAA,EAAA;AAAA,wBAAA,QAAA,CAAA,EAAA,GAAA,QAAA,CAAA,OAAA,CAAA,CAAA,CAAA,CAAA;;AAAA,4BAAA,EAWD,QAAA,CAAA,EAAA,CAAA,OAAA,KAXC,SAAA,CAAA,EAAA;AAAA,0BAAA,QAAA,CAAA,IAAA,GAAA,EAAA;AAAA;AAAA;;AAAA,+BAAA,QAAA,CAAA,MAAA,CAAA,QAAA,EAYIE,SAAS,CAATA,aAAAA,CAAwB,CAAA,GAAA,iBAAA,CAAA,OAAA,EAAA,QAAA,CAZ5B,EAY4B,CAAxBA,CAZJ,CAAA;;AAAA,2BAAA,EAAA;AAgBPA,wBAAAA,SAAS,CAATA,aAAAA,CAAwB,CAAA,GAAA,kBAAA,CAAA,OAAA,EAAxBA,KAAwB,CAAxBA;;AAhBO,2BAAA,EAAA;AAAA,2BAAA,KAAA;AAAA,+BAAA,QAAA,CAAA,IAAA,EAAA;AAAA;AAAA;AAAA,iBAAA,EAAA,OAAA,EAAA,IAAA,EAAA,CAAA,CAAA,CAAA,EAAA,EAAA,CAAA,CAAA,CAAA;AAAD,eAAA,CAAA;AAFH,aAAP;AALa,WACQ,CADR;AAAA,cACPL,MADO,GAAA,KAAA,CAAA,MAAA,CAAA,CA4Bf;;;AACAA,UAAAA,MAAM,CAANA,KAAAA,CAAa,UAAA,KAAA,EAAS;AACpB,gBAAI,CAAC,cAAA,IAAA,CAAoBM,KAAK,CAA9B,OAAK,CAAL,EAAyC;AACvC,oBAAA,KAAA;AACD;AAHHN,WAAAA;AAKD;AA3DQ,OAAA,CAAA;AAAA,aAAA,eAAA;AAAA,KAAA,CAcmBD,kBAAAA,CAdnB,OAAA,CAAA;;AA8DX,KAAA,GAAA,kBAAA,CAAA,oBAAA,EAAA,eAAA,EAAA,eAAA;AAEA,WAAO;AACLP,MAAAA,iBAAiB,EADZ,iBAAA;AAELC,MAAAA,iBAAiB,EAFZ,iBAAA;AAGLc,MAAAA,eAAe,EAAE,IAHZ,eAGY,EAHZ;AAILC,MAAAA,wBAAwB,EAAEC,oCAAAA,CAAAA;AAJrB,KAAP;AAhEF,GAAA;AAuED","sourcesContent":["/* eslint class-methods-use-this: [\"error\", { \"exceptMethods\": [\"cancel\", \"getVoices\", \"speak\"] }] */\n\nimport { createSpeechRecognitionPonyfillFromRecognizer } from 'web-speech-cognitive-services/lib/SpeechServices/SpeechToText';\n\nimport AbortController from 'abort-controller-es5';\nimport createCustomEvent from './createCustomEvent';\nimport createErrorEvent from './createErrorEvent';\nimport createTaskQueue from './createTaskQueue';\nimport EventTargetShim, { defineEventAttribute } from 'event-target-shim-es5';\nimport playCognitiveServicesStream from './playCognitiveServicesStream';\nimport playWhiteNoise from './playWhiteNoise';\nimport SpeechSynthesisAudioStreamUtterance from './SpeechSynthesisAudioStreamUtterance';\n\nexport default function({\n  audioContext,\n  enableTelemetry,\n  ponyfill = {\n    AudioContext: window.AudioContext || window.webkitAudioContext\n  },\n  recognizer,\n  textNormalization\n}) {\n  if (!ponyfill.AudioContext) {\n    console.warn(\n      'botframework-directlinespeech-sdk: This browser does not support Web Audio API. Speech support is disabled.'\n    );\n\n    return () => ({});\n  }\n\n  return () => {\n    const { SpeechGrammarList, SpeechRecognition } = createSpeechRecognitionPonyfillFromRecognizer({\n      createRecognizer: () => recognizer,\n      enableTelemetry,\n      looseEvents: true,\n      textNormalization\n    });\n\n    if (!audioContext) {\n      audioContext = new ponyfill.AudioContext();\n    }\n\n    const { cancelAll, push } = createTaskQueue();\n\n    class SpeechSynthesis extends EventTargetShim {\n      cancel() {\n        cancelAll();\n      }\n\n      // Returns an empty array.\n      // Synthesis is done on the bot side, the content of the voice list is not meaningful on the client side.\n      getVoices() {\n        return [];\n      }\n\n      speak(utterance) {\n        const { result } = push(() => {\n          const controller = new AbortController();\n          const { signal } = controller;\n\n          return {\n            abort: controller.abort.bind(controller),\n            result: (async () => {\n              utterance.dispatchEvent(createCustomEvent('start'));\n\n              try {\n                if (utterance.audioStream) {\n                  await playCognitiveServicesStream(audioContext, utterance.audioStream, { signal });\n                } else {\n                  await playWhiteNoise(audioContext);\n                }\n              } catch (error) {\n                // Either dispatch \"end\" or \"error\" event, but not both\n                if (error.message !== 'aborted') {\n                  return utterance.dispatchEvent(createErrorEvent(error));\n                }\n              }\n\n              utterance.dispatchEvent(createCustomEvent('end'));\n            })()\n          };\n        });\n\n        // Catching the error to prevent uncaught promise error due to cancellation.\n        result.catch(error => {\n          if (!/^cancelled/iu.test(error.message)) {\n            throw error;\n          }\n        });\n      }\n    }\n\n    defineEventAttribute(SpeechSynthesis, 'voiceschanged');\n\n    return {\n      SpeechGrammarList,\n      SpeechRecognition,\n      speechSynthesis: new SpeechSynthesis(),\n      SpeechSynthesisUtterance: SpeechSynthesisAudioStreamUtterance\n    };\n  };\n}\n"],"sourceRoot":"directlinespeech:///"},"metadata":{},"sourceType":"script"}