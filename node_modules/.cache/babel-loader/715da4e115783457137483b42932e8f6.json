{"ast":null,"code":"\"use strict\";\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\");\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = create;\n\nvar _regenerator = _interopRequireDefault(require(\"@babel/runtime/regenerator\"));\n\nvar _asyncToGenerator2 = _interopRequireDefault(require(\"@babel/runtime/helpers/asyncToGenerator\"));\n\nvar _AudioConfig = require(\"microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioConfig\");\n\nvar _microsoftCognitiveservicesSpeechSdk = require(\"microsoft-cognitiveservices-speech-sdk\");\n\nvar _MicAudioSource = require(\"microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/MicAudioSource\");\n\nvar _createWebSpeechPonyfillFactory = _interopRequireDefault(require(\"./createWebSpeechPonyfillFactory\"));\n\nvar _DirectLineSpeech = _interopRequireDefault(require(\"./DirectLineSpeech\"));\n\nvar _patchDialogServiceConnectorInline = _interopRequireDefault(require(\"./patchDialogServiceConnectorInline\"));\n\nvar _refreshDirectLineToken = _interopRequireDefault(require(\"./utils/refreshDirectLineToken\"));\n\nvar _resolveFunctionOrReturnValue = _interopRequireDefault(require(\"./resolveFunctionOrReturnValue\"));\n/* eslint complexity: [\"error\", 33] */\n\n\nvar DIRECT_LINE_TOKEN_RENEWAL_INTERVAL = 900000; // 15 minutes\n\nvar TOKEN_RENEWAL_INTERVAL = 120000;\n\nfunction create(_x) {\n  return _create.apply(this, arguments);\n}\n\nfunction _create() {\n  _create = (0, _asyncToGenerator2.default)( /*#__PURE__*/_regenerator.default.mark(function _callee3(_ref) {\n    var audioConfig, audioContext, audioInputDeviceId, enableInternalHTTPSupport, enableTelemetry, fetchCredentials, speechRecognitionEndpointId, _ref$speechRecognitio, speechRecognitionLanguage, speechSynthesisDeploymentId, speechSynthesisOutputFormat, textNormalization, userID, username, _yield$resolveFunctio, authorizationToken, directLineToken, region, subscriptionKey, _audioConfig, source, config, dialogServiceConnector, interval, _interval, directLine, webSpeechPonyfillFactory;\n\n    return _regenerator.default.wrap(function _callee3$(_context3) {\n      while (1) {\n        switch (_context3.prev = _context3.next) {\n          case 0:\n            audioConfig = _ref.audioConfig, audioContext = _ref.audioContext, audioInputDeviceId = _ref.audioInputDeviceId, enableInternalHTTPSupport = _ref.enableInternalHTTPSupport, enableTelemetry = _ref.enableTelemetry, fetchCredentials = _ref.fetchCredentials, speechRecognitionEndpointId = _ref.speechRecognitionEndpointId, _ref$speechRecognitio = _ref.speechRecognitionLanguage, speechRecognitionLanguage = _ref$speechRecognitio === void 0 ? typeof window !== 'undefined' && typeof window.navigator !== 'undefined' && window.navigator.language || 'en-US' : _ref$speechRecognitio, speechSynthesisDeploymentId = _ref.speechSynthesisDeploymentId, speechSynthesisOutputFormat = _ref.speechSynthesisOutputFormat, textNormalization = _ref.textNormalization, userID = _ref.userID, username = _ref.username;\n\n            if (fetchCredentials) {\n              _context3.next = 3;\n              break;\n            }\n\n            throw new Error('\"fetchCredentials\" must be specified.');\n\n          case 3:\n            _context3.next = 5;\n            return (0, _resolveFunctionOrReturnValue.default)(fetchCredentials);\n\n          case 5:\n            _yield$resolveFunctio = _context3.sent;\n            authorizationToken = _yield$resolveFunctio.authorizationToken;\n            directLineToken = _yield$resolveFunctio.directLineToken;\n            region = _yield$resolveFunctio.region;\n            subscriptionKey = _yield$resolveFunctio.subscriptionKey;\n\n            if (!(!authorizationToken && !subscriptionKey || authorizationToken && subscriptionKey || authorizationToken && typeof authorizationToken !== 'string' || subscriptionKey && typeof subscriptionKey !== 'string' || enableInternalHTTPSupport && !directLineToken)) {\n              _context3.next = 12;\n              break;\n            }\n\n            throw new Error('\"fetchCredentials\" must return either \"authorizationToken\" or \"subscriptionKey\" as a non-empty string only. If enableInternalHTTPSupport is set to true, then it should also return a non-empty \"directLineToken\"');\n\n          case 12:\n            if (typeof enableTelemetry !== 'undefined') {\n              console.warn('botframework-directlinespeech: Telemetry options are not yet supported. Please refer to Cognitive Services documentation for details.');\n            }\n\n            if (!(!region || typeof region !== 'string')) {\n              _context3.next = 15;\n              break;\n            }\n\n            throw new Error('\"fetchCredentials\" must return \"region\" as a non-empty string.');\n\n          case 15:\n            if (audioConfig && audioInputDeviceId) {\n              console.warn('botframework-directlinespeech-sdk: Only \"audioConfig\" or \"audioInputDeviceId\" can be specified, but not both; ignoring \"audioInputDeviceId\".');\n            } else if (!audioConfig) {\n              if (audioInputDeviceId) {\n                audioConfig = _AudioConfig.AudioConfig.fromMicrophoneInput(audioInputDeviceId);\n              } else {\n                audioConfig = _AudioConfig.AudioConfig.fromDefaultMicrophoneInput();\n              } // WORKAROUND: In Speech SDK 1.12.0-1.13.1, it dropped support of macOS/iOS Safari.\n              //             This code is adopted from microsoft-cognitiveservices-speech-sdk/src/common.browser/MicAudioSource.ts.\n              //             We will not need this code when using Speech SDK 1.14.0 or up.\n              // TODO: [P1] #3575 Remove the following lines when bumping to Speech SDK 1.14.0 or higher\n\n\n              _audioConfig = audioConfig, source = _audioConfig.privSource;\n\n              source.createAudioContext = function () {\n                if (!!source.privContext) {\n                  return;\n                }\n\n                var AudioContext = window.AudioContext || window.webkitAudioContext;\n\n                if (typeof AudioContext === 'undefined') {\n                  throw new Error('Browser does not support Web Audio API (AudioContext/webkitAudioContext is not available).');\n                }\n\n                if (navigator.mediaDevices.getSupportedConstraints().sampleRate) {\n                  source.privContext = new AudioContext({\n                    sampleRate: _MicAudioSource.MicAudioSource.AUDIOFORMAT.samplesPerSec\n                  });\n                } else {\n                  source.privContext = new AudioContext();\n                }\n              };\n            }\n\n            if (speechRecognitionEndpointId) {\n              console.warn('botframework-directlinespeech: Custom Speech is currently not supported; ignoring \"speechRecognitionEndpointId\".');\n            }\n\n            if (speechSynthesisDeploymentId) {\n              console.warn('botframework-directlinespeech: Custom Voice is currently not supported; ignoring \"speechSynthesisDeploymentId\".');\n            }\n\n            if (speechSynthesisOutputFormat) {\n              console.warn('botframework-directlinespeech: Synthesis output format is currently not supported; ignoring \"speechSynthesisOutputFormat\".');\n            }\n\n            if (textNormalization) {\n              console.warn('botframework-directlinespeech: Text normalization is currently not supported; ignoring \"textNormalization\".');\n            }\n\n            if (userID || username) {\n              console.warn('botframework-directlinespeech: Custom \"userId\" and \"username\" are currently not supported and are ignored.');\n            }\n\n            if (authorizationToken) {\n              config = _microsoftCognitiveservicesSpeechSdk.BotFrameworkConfig.fromAuthorizationToken(authorizationToken, region);\n            } else {\n              config = _microsoftCognitiveservicesSpeechSdk.BotFrameworkConfig.fromSubscription(subscriptionKey, region);\n            } // If internal HTTP support is enabled, switch the endpoint to Direct Line on Direct Line Speech service.\n\n\n            if (enableInternalHTTPSupport) {\n              config.setProperty(_microsoftCognitiveservicesSpeechSdk.PropertyId.SpeechServiceConnection_Endpoint, \"wss://\".concat(encodeURI(region), \".convai.speech.microsoft.com/directline/api/v1\"));\n              config.setProperty(_microsoftCognitiveservicesSpeechSdk.PropertyId.Conversation_ApplicationId, directLineToken);\n            } // Supported options can be found in DialogConnectorFactory.js.\n            // Set the language used for recognition.\n\n\n            config.setProperty(_microsoftCognitiveservicesSpeechSdk.PropertyId.SpeechServiceConnection_RecoLanguage, speechRecognitionLanguage); // The following code sets the output format.\n            // As advised by the Speech team, this API may be subject to future changes.\n            // We are not enabling output format option because it does not send detailed output format to the bot, rendering this option useless.\n            // config.setProperty(PropertyId.SpeechServiceResponse_OutputFormatOption, OutputFormat[OutputFormat.Detailed]);\n            // Set the user ID for starting the conversation.\n\n            userID && config.setProperty(_microsoftCognitiveservicesSpeechSdk.PropertyId.Conversation_From_Id, userID); // Set Custom Speech and Custom Voice.\n            // The following code is copied from C#, and it is not working yet.\n            // https://github.com/Azure-Samples/Cognitive-Services-Direct-Line-Speech-Client/blob/master/DLSpeechClient/MainWindow.xaml.cs\n            // speechRecognitionEndpointId && config.setServiceProperty('cid', speechRecognitionEndpointId, ServicePropertyChannel.UriQueryParameter);\n            // speechSynthesisDeploymentId && config.setProperty(PropertyId.conversation_Custom_Voice_Deployment_Ids, speechSynthesisDeploymentId);\n\n            dialogServiceConnector = (0, _patchDialogServiceConnectorInline.default)(new _microsoftCognitiveservicesSpeechSdk.DialogServiceConnector(config, audioConfig));\n            dialogServiceConnector.connect(); // Renew token per interval.\n\n            if (authorizationToken) {\n              interval = setInterval( /*#__PURE__*/(0, _asyncToGenerator2.default)( /*#__PURE__*/_regenerator.default.mark(function _callee() {\n                var _yield$resolveFunctio2, authorizationToken, nextRegion;\n\n                return _regenerator.default.wrap(function _callee$(_context) {\n                  while (1) {\n                    switch (_context.prev = _context.next) {\n                      case 0:\n                        // #2660 If the connector has been disposed, we should stop renewing the token.\n                        // TODO: We should use a public implementation if Speech SDK has one related to \"privIsDisposed\".\n                        if (dialogServiceConnector.privIsDisposed) {\n                          clearInterval(interval);\n                        }\n\n                        _context.next = 3;\n                        return (0, _resolveFunctionOrReturnValue.default)(fetchCredentials);\n\n                      case 3:\n                        _yield$resolveFunctio2 = _context.sent;\n                        authorizationToken = _yield$resolveFunctio2.authorizationToken;\n                        nextRegion = _yield$resolveFunctio2.region;\n\n                        if (authorizationToken) {\n                          _context.next = 8;\n                          break;\n                        }\n\n                        return _context.abrupt(\"return\", console.warn('botframework-directlinespeech-sdk: Renew token failed because \"fetchCredentials\" call returned no authorization token.'));\n\n                      case 8:\n                        if (!(region !== nextRegion)) {\n                          _context.next = 10;\n                          break;\n                        }\n\n                        return _context.abrupt(\"return\", console.warn('botframework-directlinespeech-sdk: Region change is not supported for renewed token. Authorization token is not renewed.'));\n\n                      case 10:\n                        dialogServiceConnector.authorizationToken = authorizationToken;\n                      // eslint-disable-line require-atomic-updates\n\n                      case 11:\n                      case \"end\":\n                        return _context.stop();\n                    }\n                  }\n                }, _callee);\n              })), TOKEN_RENEWAL_INTERVAL);\n            } // Renew token per interval.\n\n\n            if (enableInternalHTTPSupport) {\n              _interval = setInterval( /*#__PURE__*/(0, _asyncToGenerator2.default)( /*#__PURE__*/_regenerator.default.mark(function _callee2() {\n                var refreshedDirectLineToken;\n                return _regenerator.default.wrap(function _callee2$(_context2) {\n                  while (1) {\n                    switch (_context2.prev = _context2.next) {\n                      case 0:\n                        // #2660 If the connector has been disposed, we should stop renewing the token.\n                        // TODO: We should use a public implementation if Speech SDK has one related to \"privIsDisposed\".\n                        if (dialogServiceConnector.privIsDisposed) {\n                          clearInterval(_interval);\n                        }\n\n                        _context2.next = 3;\n                        return (0, _refreshDirectLineToken.default)(directLineToken);\n\n                      case 3:\n                        refreshedDirectLineToken = _context2.sent;\n\n                        if (refreshedDirectLineToken) {\n                          _context2.next = 6;\n                          break;\n                        }\n\n                        return _context2.abrupt(\"return\", console.warn('botframework-directlinespeech-sdk: Renew token failed because call to refresh token Direct Line API did not return a new token.'));\n\n                      case 6:\n                        config.setProperty(_microsoftCognitiveservicesSpeechSdk.PropertyId.Conversation_ApplicationId, refreshedDirectLineToken);\n                        dialogServiceConnector.properties.setProperty(_microsoftCognitiveservicesSpeechSdk.PropertyId.Conversation_ApplicationId, refreshedDirectLineToken);\n                        dialogServiceConnector.connect();\n\n                      case 9:\n                      case \"end\":\n                        return _context2.stop();\n                    }\n                  }\n                }, _callee2);\n              })), DIRECT_LINE_TOKEN_RENEWAL_INTERVAL);\n            }\n\n            directLine = new _DirectLineSpeech.default({\n              dialogServiceConnector: dialogServiceConnector\n            });\n            webSpeechPonyfillFactory = (0, _createWebSpeechPonyfillFactory.default)({\n              audioContext: audioContext,\n              enableTelemetry: enableTelemetry,\n              recognizer: dialogServiceConnector,\n              textNormalization: textNormalization\n            });\n            return _context3.abrupt(\"return\", {\n              directLine: directLine,\n              webSpeechPonyfillFactory: webSpeechPonyfillFactory\n            });\n\n          case 32:\n          case \"end\":\n            return _context3.stop();\n        }\n      }\n    }, _callee3);\n  }));\n  return _create.apply(this, arguments);\n}","map":{"version":3,"sources":["../src/createAdapters.js"],"names":["DIRECT_LINE_TOKEN_RENEWAL_INTERVAL","TOKEN_RENEWAL_INTERVAL","create","audioConfig","audioContext","audioInputDeviceId","enableInternalHTTPSupport","enableTelemetry","fetchCredentials","speechRecognitionEndpointId","speechRecognitionLanguage","window","speechSynthesisDeploymentId","speechSynthesisOutputFormat","textNormalization","userID","username","authorizationToken","directLineToken","region","subscriptionKey","console","AudioConfig","source","AudioContext","navigator","sampleRate","MicAudioSource","samplesPerSec","config","BotFrameworkConfig","PropertyId","encodeURI","dialogServiceConnector","DialogServiceConnector","interval","setInterval","clearInterval","nextRegion","refreshedDirectLineToken","directLine","DirectLineSpeech","webSpeechPonyfillFactory","recognizer"],"mappings":";;;;;;;;;;;;;AAEA,IAAA,YAAA,GAAA,OAAA,CAAA,8EAAA,CAAA;;AACA,IAAA,oCAAA,GAAA,OAAA,CAAA,wCAAA,CAAA;;AACA,IAAA,eAAA,GAAA,OAAA,CAAA,sFAAA,CAAA;;AAEA,IAAA,+BAAA,GAAA,sBAAA,CAAA,OAAA,CAAA,kCAAA,CAAA,CAAA;;AACA,IAAA,iBAAA,GAAA,sBAAA,CAAA,OAAA,CAAA,oBAAA,CAAA,CAAA;;AACA,IAAA,kCAAA,GAAA,sBAAA,CAAA,OAAA,CAAA,qCAAA,CAAA,CAAA;;AACA,IAAA,uBAAA,GAAA,sBAAA,CAAA,OAAA,CAAA,gCAAA,CAAA,CAAA;;AACA,IAAA,6BAAA,GAAA,sBAAA,CAAA,OAAA,CAAA,gCAAA,CAAA,CAAA;AAVA;;;AAYA,IAAMA,kCAAkC,GAAxC,MAAA,C,CAAmD;;AACnD,IAAMC,sBAAsB,GAA5B,MAAA;;SAE8BC,M;;;;;oFAAf,SAAA,QAAA,CAAA,IAAA,EAAA;AAAA,QAAA,WAAA,EAAA,YAAA,EAAA,kBAAA,EAAA,yBAAA,EAAA,eAAA,EAAA,gBAAA,EAAA,2BAAA,EAAA,qBAAA,EAAA,yBAAA,EAAA,2BAAA,EAAA,2BAAA,EAAA,iBAAA,EAAA,MAAA,EAAA,QAAA,EAAA,qBAAA,EAAA,kBAAA,EAAA,eAAA,EAAA,MAAA,EAAA,eAAA,EAAA,YAAA,EAAA,MAAA,EAAA,MAAA,EAAA,sBAAA,EAAA,QAAA,EAAA,SAAA,EAAA,UAAA,EAAA,wBAAA;;AAAA,WAAA,YAAA,CAAA,OAAA,CAAA,IAAA,CAAA,SAAA,SAAA,CAAA,SAAA,EAAA;AAAA,aAAA,CAAA,EAAA;AAAA,gBAAA,SAAA,CAAA,IAAA,GAAA,SAAA,CAAA,IAAA;AAAA,eAAA,CAAA;AACbC,YAAAA,WADa,GAAA,IAAA,CAAA,WACbA,EACAC,YAFa,GAAA,IAAA,CAAA,YACbD,EAEAE,kBAHa,GAAA,IAAA,CAAA,kBACbF,EAGAG,yBAJa,GAAA,IAAA,CAAA,yBACbH,EAIAI,eALa,GAAA,IAAA,CAAA,eACbJ,EAKAK,gBANa,GAAA,IAAA,CAAA,gBACbL,EAMAM,2BAPa,GAAA,IAAA,CAAA,2BACbN,EADa,qBAAA,GAAA,IAAA,CAAA,yBACbA,EAOAO,yBARa,GAAA,qBAAA,KAAA,KAAA,CAAA,GAQgB,OAAA,MAAA,KAAA,WAAA,IAC3B,OAAOC,MAAM,CAAb,SAAA,KAD2B,WAAA,IAE3BA,MAAM,CAANA,SAAAA,CAF0B,QAAC,IARhB,OAAA,GAAA,qBACbR,EAWAS,2BAZa,GAAA,IAAA,CAAA,2BACbT,EAYAU,2BAba,GAAA,IAAA,CAAA,2BACbV,EAaAW,iBAda,GAAA,IAAA,CAAA,iBACbX,EAcAY,MAfa,GAAA,IAAA,CAAA,MACbZ,EAeAa,QAhBa,GAAA,IAAA,CAAA,QACbb;;AADa,gBAAA,gBAAA,EAAA;AAAA,cAAA,SAAA,CAAA,IAAA,GAAA,CAAA;AAAA;AAAA;;AAAA,kBAmBL,IAAA,KAAA,CAnBK,uCAmBL,CAnBK;;AAAA,eAAA,CAAA;AAAA,YAAA,SAAA,CAAA,IAAA,GAAA,CAAA;AAAA,mBAsBkE,CAAA,GAAA,6BAAA,CAAA,OAAA,EAtBlE,gBAsBkE,CAtBlE;;AAAA,eAAA,CAAA;AAAA,YAAA,qBAAA,GAAA,SAAA,CAAA,IAAA;AAsBLc,YAAAA,kBAtBK,GAAA,qBAAA,CAAA,kBAsBLA;AAAoBC,YAAAA,eAtBf,GAAA,qBAAA,CAAA,eAsBeA;AAAiBC,YAAAA,MAtBhC,GAAA,qBAAA,CAAA,MAsBgCA;AAAQC,YAAAA,eAtBxC,GAAA,qBAAA,CAAA,eAsBwCA;;AAtBxC,gBAAA,EA2BV,CAAA,kBAAA,IAAuB,CAAxB,eAAC,IACAH,kBAAkB,IADnB,eAAC,IAEAA,kBAAkB,IAAI,OAAA,kBAAA,KAFvB,QAAC,IAGAG,eAAe,IAAI,OAAA,eAAA,KAHpB,QAAC,IAIAd,yBAAyB,IAAI,CA/BnB,eAAA,CAAA,EAAA;AAAA,cAAA,SAAA,CAAA,IAAA,GAAA,EAAA;AAAA;AAAA;;AAAA,kBAiCL,IAAA,KAAA,CAjCK,mNAiCL,CAjCK;;AAAA,eAAA,EAAA;AAsCb,gBAAI,OAAA,eAAA,KAAJ,WAAA,EAA4C;AAC1Ce,cAAAA,OAAO,CAAPA,IAAAA,CAAAA,uIAAAA;AAGD;;AA1CY,gBAAA,EA4CT,CAAA,MAAA,IAAW,OAAA,MAAA,KA5CF,QAAA,CAAA,EAAA;AAAA,cAAA,SAAA,CAAA,IAAA,GAAA,EAAA;AAAA;AAAA;;AAAA,kBA6CL,IAAA,KAAA,CA7CK,gEA6CL,CA7CK;;AAAA,eAAA,EAAA;AAgDb,gBAAIlB,WAAW,IAAf,kBAAA,EAAuC;AACrCkB,cAAAA,OAAO,CAAPA,IAAAA,CAAAA,8IAAAA;AADF,aAAA,MAIO,IAAI,CAAJ,WAAA,EAAkB;AACvB,kBAAA,kBAAA,EAAwB;AACtBlB,gBAAAA,WAAW,GAAGmB,YAAAA,CAAAA,WAAAA,CAAAA,mBAAAA,CAAdnB,kBAAcmB,CAAdnB;AADF,eAAA,MAEO;AACLA,gBAAAA,WAAW,GAAGmB,YAAAA,CAAAA,WAAAA,CAAdnB,0BAAcmB,EAAdnB;AAJqB,eAAA,CAOvB;AACA;AACA;AACA;;;AAVuB,cAAA,YAAA,GAAA,WAAA,EAWHoB,MAXG,GAAA,YAAA,CAAA,UAAA;;AAavBA,cAAAA,MAAM,CAANA,kBAAAA,GAA4B,YAAM;AAChC,oBAAI,CAAC,CAACA,MAAM,CAAZ,WAAA,EAA0B;AACxB;AACD;;AAED,oBAAMC,YAAY,GAAGb,MAAM,CAANA,YAAAA,IAAuBA,MAAM,CAAlD,kBAAA;;AAEA,oBAAI,OAAA,YAAA,KAAJ,WAAA,EAAyC;AACvC,wBAAM,IAAA,KAAA,CAAN,4FAAM,CAAN;AACD;;AAED,oBAAIc,SAAS,CAATA,YAAAA,CAAAA,uBAAAA,GAAJ,UAAA,EAAiE;AAC/DF,kBAAAA,MAAM,CAANA,WAAAA,GAAqB,IAAA,YAAA,CAAiB;AAAEG,oBAAAA,UAAU,EAAEC,eAAAA,CAAAA,cAAAA,CAAAA,WAAAA,CAA2BC;AAAzC,mBAAjB,CAArBL;AADF,iBAAA,MAEO;AACLA,kBAAAA,MAAM,CAANA,WAAAA,GAAqB,IAArBA,YAAqB,EAArBA;AACD;AAfHA,eAAAA;AAiBD;;AAED,gBAAA,2BAAA,EAAiC;AAC/BF,cAAAA,OAAO,CAAPA,IAAAA,CAAAA,kHAAAA;AAGD;;AAED,gBAAA,2BAAA,EAAiC;AAC/BA,cAAAA,OAAO,CAAPA,IAAAA,CAAAA,iHAAAA;AAGD;;AAED,gBAAA,2BAAA,EAAiC;AAC/BA,cAAAA,OAAO,CAAPA,IAAAA,CAAAA,4HAAAA;AAGD;;AAED,gBAAA,iBAAA,EAAuB;AACrBA,cAAAA,OAAO,CAAPA,IAAAA,CAAAA,6GAAAA;AAGD;;AAED,gBAAIN,MAAM,IAAV,QAAA,EAAwB;AACtBM,cAAAA,OAAO,CAAPA,IAAAA,CAAAA,4GAAAA;AAGD;;AAID,gBAAA,kBAAA,EAAwB;AACtBQ,cAAAA,MAAM,GAAGC,oCAAAA,CAAAA,kBAAAA,CAAAA,sBAAAA,CAAAA,kBAAAA,EAATD,MAASC,CAATD;AADF,aAAA,MAEO;AACLA,cAAAA,MAAM,GAAGC,oCAAAA,CAAAA,kBAAAA,CAAAA,gBAAAA,CAAAA,eAAAA,EAATD,MAASC,CAATD;AAvHW,aAAA,CA0Hb;;;AACA,gBAAA,yBAAA,EAA+B;AAC7BA,cAAAA,MAAM,CAANA,WAAAA,CACEE,oCAAAA,CAAAA,UAAAA,CADFF,gCAAAA,EAAAA,SAAAA,MAAAA,CAEWG,SAAS,CAFpBH,MAEoB,CAFpBA,EAAAA,gDAAAA,CAAAA;AAKAA,cAAAA,MAAM,CAANA,WAAAA,CAAmBE,oCAAAA,CAAAA,UAAAA,CAAnBF,0BAAAA,EAAAA,eAAAA;AAjIW,aAAA,CAoIb;AAEA;;;AACAA,YAAAA,MAAM,CAANA,WAAAA,CAAmBE,oCAAAA,CAAAA,UAAAA,CAAnBF,oCAAAA,EAvIa,yBAuIbA,EAvIa,CAyIb;AACA;AACA;AACA;AAEA;;AACAd,YAAAA,MAAM,IAAIc,MAAM,CAANA,WAAAA,CAAmBE,oCAAAA,CAAAA,UAAAA,CAAnBF,oBAAAA,EA/IG,MA+IHA,CAAVd,CA/Ia,CAiJb;AACA;AACA;AACA;AACA;;AAEMkB,YAAAA,sBAvJO,GAuJkB,CAAA,GAAA,kCAAA,CAAA,OAAA,EAAkC,IAAIC,oCAAAA,CAAJ,sBAAA,CAAA,MAAA,EAvJpD,WAuJoD,CAAlC,CAAzBD;AAENA,YAAAA,sBAAsB,CAzJT,OAyJbA,GAzJa,CA2Jb;;AACA,gBAAA,kBAAA,EAAwB;AAChBE,cAAAA,QADgB,GACLC,WAAW,EAAA,aAAA,CAAA,GAAA,kBAAA,CAAA,OAAA,GAAA,aAAA,YAAA,CAAA,OAAA,CAAA,IAAA,CAAC,SAAA,OAAA,GAAA;AAAA,oBAAA,sBAAA,EAAA,kBAAA,EAAA,UAAA;;AAAA,uBAAA,YAAA,CAAA,OAAA,CAAA,IAAA,CAAA,SAAA,QAAA,CAAA,QAAA,EAAA;AAAA,yBAAA,CAAA,EAAA;AAAA,4BAAA,QAAA,CAAA,IAAA,GAAA,QAAA,CAAA,IAAA;AAAA,2BAAA,CAAA;AAC3B;AAEA;AACA,4BAAIH,sBAAsB,CAA1B,cAAA,EAA2C;AACzCI,0BAAAA,aAAa,CAAbA,QAAa,CAAbA;AACD;;AAN0B,wBAAA,QAAA,CAAA,IAAA,GAAA,CAAA;AAAA,+BAQ8B,CAAA,GAAA,6BAAA,CAAA,OAAA,EAR9B,gBAQ8B,CAR9B;;AAAA,2BAAA,CAAA;AAAA,wBAAA,sBAAA,GAAA,QAAA,CAAA,IAAA;AAQnBpB,wBAAAA,kBARmB,GAAA,sBAAA,CAAA,kBAQnBA;AAA4BqB,wBAAAA,UART,GAAA,sBAAA,CAAA,MAQSA;;AART,4BAAA,kBAAA,EAAA;AAAA,0BAAA,QAAA,CAAA,IAAA,GAAA,CAAA;AAAA;AAAA;;AAAA,+BAAA,QAAA,CAAA,MAAA,CAAA,QAAA,EAWlBjB,OAAO,CAAPA,IAAAA,CAXkB,wHAWlBA,CAXkB,CAAA;;AAAA,2BAAA,CAAA;AAAA,4BAAA,EAgBvBF,MAAM,KAhBiB,UAAA,CAAA,EAAA;AAAA,0BAAA,QAAA,CAAA,IAAA,GAAA,EAAA;AAAA;AAAA;;AAAA,+BAAA,QAAA,CAAA,MAAA,CAAA,QAAA,EAiBlBE,OAAO,CAAPA,IAAAA,CAjBkB,0HAiBlBA,CAjBkB,CAAA;;AAAA,2BAAA,EAAA;AAsB3BY,wBAAAA,sBAAsB,CAAtBA,kBAAAA,GAtB2B,kBAsB3BA;AAAgE;;AAtBrC,2BAAA,EAAA;AAAA,2BAAA,KAAA;AAAA,+BAAA,QAAA,CAAA,IAAA,EAAA;AAAA;AAAA;AAAA,iBAAA,EAAA,OAAA,CAAA;AAAD,eAAA,CAAA,CAAA,EADN,sBACM,CAAtBE;AA7JK,aAAA,CAuLb;;;AACA,gBAAA,yBAAA,EAA+B;AACvBA,cAAAA,SADuB,GACZC,WAAW,EAAA,aAAA,CAAA,GAAA,kBAAA,CAAA,OAAA,GAAA,aAAA,YAAA,CAAA,OAAA,CAAA,IAAA,CAAC,SAAA,QAAA,GAAA;AAAA,oBAAA,wBAAA;AAAA,uBAAA,YAAA,CAAA,OAAA,CAAA,IAAA,CAAA,SAAA,SAAA,CAAA,SAAA,EAAA;AAAA,yBAAA,CAAA,EAAA;AAAA,4BAAA,SAAA,CAAA,IAAA,GAAA,SAAA,CAAA,IAAA;AAAA,2BAAA,CAAA;AAC3B;AAEA;AACA,4BAAIH,sBAAsB,CAA1B,cAAA,EAA2C;AACzCI,0BAAAA,aAAa,CAAbA,SAAa,CAAbA;AACD;;AAN0B,wBAAA,SAAA,CAAA,IAAA,GAAA,CAAA;AAAA,+BAQY,CAAA,GAAA,uBAAA,CAAA,OAAA,EARZ,eAQY,CARZ;;AAAA,2BAAA,CAAA;AAQrBE,wBAAAA,wBARqB,GAAA,SAAA,CAAA,IAQrBA;;AARqB,4BAAA,wBAAA,EAAA;AAAA,0BAAA,SAAA,CAAA,IAAA,GAAA,CAAA;AAAA;AAAA;;AAAA,+BAAA,SAAA,CAAA,MAAA,CAAA,QAAA,EAWlBlB,OAAO,CAAPA,IAAAA,CAXkB,iIAWlBA,CAXkB,CAAA;;AAAA,2BAAA,CAAA;AAgB3BQ,wBAAAA,MAAM,CAANA,WAAAA,CAAmBE,oCAAAA,CAAAA,UAAAA,CAAnBF,0BAAAA,EAAAA,wBAAAA;AAEAI,wBAAAA,sBAAsB,CAAtBA,UAAAA,CAAAA,WAAAA,CAA8CF,oCAAAA,CAAAA,UAAAA,CAA9CE,0BAAAA,EAAAA,wBAAAA;AACAA,wBAAAA,sBAAsB,CAAtBA,OAAAA;;AAnB2B,2BAAA,CAAA;AAAA,2BAAA,KAAA;AAAA,+BAAA,SAAA,CAAA,IAAA,EAAA;AAAA;AAAA;AAAA,iBAAA,EAAA,QAAA,CAAA;AAAD,eAAA,CAAA,CAAA,EADC,kCACD,CAAtBE;AAqBP;;AAEKK,YAAAA,UAhNO,GAgNM,IAAIC,iBAAAA,CAAJ,OAAA,CAAqB;AAAER,cAAAA,sBAAsB,EAAtBA;AAAF,aAArB,CAAbO;AAEAE,YAAAA,wBAlNO,GAkNoB,CAAA,GAAA,+BAAA,CAAA,OAAA,EAA+B;AAC9DtC,cAAAA,YAAY,EADkD,YAAA;AAE9DG,cAAAA,eAAe,EAF+C,eAAA;AAG9DoC,cAAAA,UAAU,EAHoD,sBAAA;AAI9D7B,cAAAA,iBAAiB,EAAjBA;AAJ8D,aAA/B,CAA3B4B;AAlNO,mBAAA,SAAA,CAAA,MAAA,CAAA,QAAA,EAyNN;AACLF,cAAAA,UAAU,EADL,UAAA;AAELE,cAAAA,wBAAwB,EAAxBA;AAFK,aAzNM,CAAA;;AAAA,eAAA,EAAA;AAAA,eAAA,KAAA;AAAA,mBAAA,SAAA,CAAA,IAAA,EAAA;AAAA;AAAA;AAAA,KAAA,EAAA,QAAA,CAAA","sourcesContent":["/* eslint complexity: [\"error\", 33] */\n\nimport { AudioConfig } from 'microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioConfig';\nimport { BotFrameworkConfig, DialogServiceConnector, PropertyId } from 'microsoft-cognitiveservices-speech-sdk';\nimport { MicAudioSource } from 'microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/MicAudioSource';\n\nimport createWebSpeechPonyfillFactory from './createWebSpeechPonyfillFactory';\nimport DirectLineSpeech from './DirectLineSpeech';\nimport patchDialogServiceConnectorInline from './patchDialogServiceConnectorInline';\nimport refreshDirectLineToken from './utils/refreshDirectLineToken';\nimport resolveFunctionOrReturnValue from './resolveFunctionOrReturnValue';\n\nconst DIRECT_LINE_TOKEN_RENEWAL_INTERVAL = 900000; // 15 minutes\nconst TOKEN_RENEWAL_INTERVAL = 120000;\n\nexport default async function create({\n  audioConfig,\n  audioContext,\n  audioInputDeviceId,\n  enableInternalHTTPSupport,\n  enableTelemetry,\n  fetchCredentials,\n  speechRecognitionEndpointId,\n  speechRecognitionLanguage = (typeof window !== 'undefined' &&\n    typeof window.navigator !== 'undefined' &&\n    window.navigator.language) ||\n    'en-US',\n  speechSynthesisDeploymentId,\n  speechSynthesisOutputFormat,\n  textNormalization,\n  userID,\n  username\n}) {\n  if (!fetchCredentials) {\n    throw new Error('\"fetchCredentials\" must be specified.');\n  }\n\n  const { authorizationToken, directLineToken, region, subscriptionKey } = await resolveFunctionOrReturnValue(\n    fetchCredentials\n  );\n\n  if (\n    (!authorizationToken && !subscriptionKey) ||\n    (authorizationToken && subscriptionKey) ||\n    (authorizationToken && typeof authorizationToken !== 'string') ||\n    (subscriptionKey && typeof subscriptionKey !== 'string') ||\n    (enableInternalHTTPSupport && !directLineToken)\n  ) {\n    throw new Error(\n      '\"fetchCredentials\" must return either \"authorizationToken\" or \"subscriptionKey\" as a non-empty string only. If enableInternalHTTPSupport is set to true, then it should also return a non-empty \"directLineToken\"'\n    );\n  }\n\n  if (typeof enableTelemetry !== 'undefined') {\n    console.warn(\n      'botframework-directlinespeech: Telemetry options are not yet supported. Please refer to Cognitive Services documentation for details.'\n    );\n  }\n\n  if (!region || typeof region !== 'string') {\n    throw new Error('\"fetchCredentials\" must return \"region\" as a non-empty string.');\n  }\n\n  if (audioConfig && audioInputDeviceId) {\n    console.warn(\n      'botframework-directlinespeech-sdk: Only \"audioConfig\" or \"audioInputDeviceId\" can be specified, but not both; ignoring \"audioInputDeviceId\".'\n    );\n  } else if (!audioConfig) {\n    if (audioInputDeviceId) {\n      audioConfig = AudioConfig.fromMicrophoneInput(audioInputDeviceId);\n    } else {\n      audioConfig = AudioConfig.fromDefaultMicrophoneInput();\n    }\n\n    // WORKAROUND: In Speech SDK 1.12.0-1.13.1, it dropped support of macOS/iOS Safari.\n    //             This code is adopted from microsoft-cognitiveservices-speech-sdk/src/common.browser/MicAudioSource.ts.\n    //             We will not need this code when using Speech SDK 1.14.0 or up.\n    // TODO: [P1] #3575 Remove the following lines when bumping to Speech SDK 1.14.0 or higher\n    const { privSource: source } = audioConfig;\n\n    source.createAudioContext = () => {\n      if (!!source.privContext) {\n        return;\n      }\n\n      const AudioContext = window.AudioContext || window.webkitAudioContext;\n\n      if (typeof AudioContext === 'undefined') {\n        throw new Error('Browser does not support Web Audio API (AudioContext/webkitAudioContext is not available).');\n      }\n\n      if (navigator.mediaDevices.getSupportedConstraints().sampleRate) {\n        source.privContext = new AudioContext({ sampleRate: MicAudioSource.AUDIOFORMAT.samplesPerSec });\n      } else {\n        source.privContext = new AudioContext();\n      }\n    };\n  }\n\n  if (speechRecognitionEndpointId) {\n    console.warn(\n      'botframework-directlinespeech: Custom Speech is currently not supported; ignoring \"speechRecognitionEndpointId\".'\n    );\n  }\n\n  if (speechSynthesisDeploymentId) {\n    console.warn(\n      'botframework-directlinespeech: Custom Voice is currently not supported; ignoring \"speechSynthesisDeploymentId\".'\n    );\n  }\n\n  if (speechSynthesisOutputFormat) {\n    console.warn(\n      'botframework-directlinespeech: Synthesis output format is currently not supported; ignoring \"speechSynthesisOutputFormat\".'\n    );\n  }\n\n  if (textNormalization) {\n    console.warn(\n      'botframework-directlinespeech: Text normalization is currently not supported; ignoring \"textNormalization\".'\n    );\n  }\n\n  if (userID || username) {\n    console.warn(\n      'botframework-directlinespeech: Custom \"userId\" and \"username\" are currently not supported and are ignored.'\n    );\n  }\n\n  let config;\n\n  if (authorizationToken) {\n    config = BotFrameworkConfig.fromAuthorizationToken(authorizationToken, region);\n  } else {\n    config = BotFrameworkConfig.fromSubscription(subscriptionKey, region);\n  }\n\n  // If internal HTTP support is enabled, switch the endpoint to Direct Line on Direct Line Speech service.\n  if (enableInternalHTTPSupport) {\n    config.setProperty(\n      PropertyId.SpeechServiceConnection_Endpoint,\n      `wss://${encodeURI(region)}.convai.speech.microsoft.com/directline/api/v1`\n    );\n\n    config.setProperty(PropertyId.Conversation_ApplicationId, directLineToken);\n  }\n\n  // Supported options can be found in DialogConnectorFactory.js.\n\n  // Set the language used for recognition.\n  config.setProperty(PropertyId.SpeechServiceConnection_RecoLanguage, speechRecognitionLanguage);\n\n  // The following code sets the output format.\n  // As advised by the Speech team, this API may be subject to future changes.\n  // We are not enabling output format option because it does not send detailed output format to the bot, rendering this option useless.\n  // config.setProperty(PropertyId.SpeechServiceResponse_OutputFormatOption, OutputFormat[OutputFormat.Detailed]);\n\n  // Set the user ID for starting the conversation.\n  userID && config.setProperty(PropertyId.Conversation_From_Id, userID);\n\n  // Set Custom Speech and Custom Voice.\n  // The following code is copied from C#, and it is not working yet.\n  // https://github.com/Azure-Samples/Cognitive-Services-Direct-Line-Speech-Client/blob/master/DLSpeechClient/MainWindow.xaml.cs\n  // speechRecognitionEndpointId && config.setServiceProperty('cid', speechRecognitionEndpointId, ServicePropertyChannel.UriQueryParameter);\n  // speechSynthesisDeploymentId && config.setProperty(PropertyId.conversation_Custom_Voice_Deployment_Ids, speechSynthesisDeploymentId);\n\n  const dialogServiceConnector = patchDialogServiceConnectorInline(new DialogServiceConnector(config, audioConfig));\n\n  dialogServiceConnector.connect();\n\n  // Renew token per interval.\n  if (authorizationToken) {\n    const interval = setInterval(async () => {\n      // #2660 If the connector has been disposed, we should stop renewing the token.\n\n      // TODO: We should use a public implementation if Speech SDK has one related to \"privIsDisposed\".\n      if (dialogServiceConnector.privIsDisposed) {\n        clearInterval(interval);\n      }\n\n      const { authorizationToken, region: nextRegion } = await resolveFunctionOrReturnValue(fetchCredentials);\n\n      if (!authorizationToken) {\n        return console.warn(\n          'botframework-directlinespeech-sdk: Renew token failed because \"fetchCredentials\" call returned no authorization token.'\n        );\n      }\n\n      if (region !== nextRegion) {\n        return console.warn(\n          'botframework-directlinespeech-sdk: Region change is not supported for renewed token. Authorization token is not renewed.'\n        );\n      }\n\n      dialogServiceConnector.authorizationToken = authorizationToken; // eslint-disable-line require-atomic-updates\n    }, TOKEN_RENEWAL_INTERVAL);\n  }\n\n  // Renew token per interval.\n  if (enableInternalHTTPSupport) {\n    const interval = setInterval(async () => {\n      // #2660 If the connector has been disposed, we should stop renewing the token.\n\n      // TODO: We should use a public implementation if Speech SDK has one related to \"privIsDisposed\".\n      if (dialogServiceConnector.privIsDisposed) {\n        clearInterval(interval);\n      }\n\n      const refreshedDirectLineToken = await refreshDirectLineToken(directLineToken);\n\n      if (!refreshedDirectLineToken) {\n        return console.warn(\n          'botframework-directlinespeech-sdk: Renew token failed because call to refresh token Direct Line API did not return a new token.'\n        );\n      }\n\n      config.setProperty(PropertyId.Conversation_ApplicationId, refreshedDirectLineToken);\n\n      dialogServiceConnector.properties.setProperty(PropertyId.Conversation_ApplicationId, refreshedDirectLineToken);\n      dialogServiceConnector.connect();\n    }, DIRECT_LINE_TOKEN_RENEWAL_INTERVAL);\n  }\n\n  const directLine = new DirectLineSpeech({ dialogServiceConnector });\n\n  const webSpeechPonyfillFactory = createWebSpeechPonyfillFactory({\n    audioContext,\n    enableTelemetry,\n    recognizer: dialogServiceConnector,\n    textNormalization\n  });\n\n  return {\n    directLine,\n    webSpeechPonyfillFactory\n  };\n}\n"],"sourceRoot":"directlinespeech:///"},"metadata":{},"sourceType":"script"}