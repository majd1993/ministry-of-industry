{"ast":null,"code":"\"use strict\";\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\");\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = createCognitiveServicesSpeechServicesPonyfillFactory;\n\nvar _regenerator = _interopRequireDefault(require(\"@babel/runtime/regenerator\"));\n\nvar _asyncToGenerator2 = _interopRequireDefault(require(\"@babel/runtime/helpers/asyncToGenerator\"));\n\nvar _AudioConfig = require(\"microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioConfig\");\n\nvar _MicAudioSource = require(\"microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/MicAudioSource\");\n\nvar _SpeechServices = _interopRequireDefault(require(\"web-speech-cognitive-services/lib/SpeechServices\"));\n\nfunction resolveFunction(fnOrValue) {\n  return typeof fnOrValue === 'function' ? fnOrValue() : fnOrValue;\n}\n\nfunction createCognitiveServicesSpeechServicesPonyfillFactory(_ref) {\n  var audioConfig = _ref.audioConfig,\n      audioContext = _ref.audioContext,\n      audioInputDeviceId = _ref.audioInputDeviceId,\n      authorizationToken = _ref.authorizationToken,\n      credentials = _ref.credentials,\n      enableTelemetry = _ref.enableTelemetry,\n      region = _ref.region,\n      speechRecognitionEndpointId = _ref.speechRecognitionEndpointId,\n      speechSynthesisDeploymentId = _ref.speechSynthesisDeploymentId,\n      speechSynthesisOutputFormat = _ref.speechSynthesisOutputFormat,\n      subscriptionKey = _ref.subscriptionKey,\n      textNormalization = _ref.textNormalization;\n\n  if (!window.navigator.mediaDevices && !audioConfig) {\n    console.warn('botframework-webchat: Your browser does not support Web Audio or the page is not loaded via HTTPS or localhost. Cognitive Services Speech Services is disabled. However, you may pass a custom AudioConfig to enable speech in this environment.');\n    return function () {\n      return {};\n    };\n  }\n\n  if (!credentials && (authorizationToken || region || subscriptionKey)) {\n    console.warn('botframework-webchat: \"authorizationToken\", \"region\", and \"subscriptionKey\" are deprecated and will be removed on or after 2020-12-17. Please use \"credentials\" instead.');\n\n    credentials = /*#__PURE__*/function () {\n      var _ref2 = (0, _asyncToGenerator2.default)( /*#__PURE__*/_regenerator.default.mark(function _callee() {\n        return _regenerator.default.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                if (!authorizationToken) {\n                  _context.next = 6;\n                  break;\n                }\n\n                _context.next = 3;\n                return resolveFunction(authorizationToken);\n\n              case 3:\n                _context.t0 = _context.sent;\n                _context.t1 = region;\n                return _context.abrupt(\"return\", {\n                  authorizationToken: _context.t0,\n                  region: _context.t1\n                });\n\n              case 6:\n                _context.t2 = region;\n                _context.next = 9;\n                return resolveFunction(subscriptionKey);\n\n              case 9:\n                _context.t3 = _context.sent;\n                return _context.abrupt(\"return\", {\n                  region: _context.t2,\n                  subscriptionKey: _context.t3\n                });\n\n              case 11:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee);\n      }));\n\n      return function credentials() {\n        return _ref2.apply(this, arguments);\n      };\n    }();\n  }\n\n  if (audioConfig && audioInputDeviceId) {\n    console.warn('botframework-webchat: \"audioConfig\" and \"audioInputDeviceId\" cannot be set at the same time; ignoring \"audioInputDeviceId\".');\n  } // WORKAROUND: We should prevent AudioContext object from being recreated because they may be blessed and UX-wise expensive to recreate.\n  //             In Cognitive Services SDK, if they detect the \"end\" function is falsy, they will not call \"end\" but \"suspend\" instead.\n  //             And on next recognition, they will re-use the AudioContext object.\n\n\n  if (!audioConfig) {\n    audioConfig = audioInputDeviceId ? _AudioConfig.AudioConfig.fromMicrophoneInput(audioInputDeviceId) : _AudioConfig.AudioConfig.fromDefaultMicrophoneInput();\n    var source = audioConfig.privSource; // WORKAROUND: In Speech SDK 1.12.0-1.13.1, it dropped support of macOS/iOS Safari.\n    //             This code is adopted from microsoft-cognitiveservices-speech-sdk/src/common.browser/MicAudioSource.ts.\n    //             We will not need this code when using Speech SDK 1.14.0 or up.\n    // TODO: [P1] #3575 Remove the following lines when bumping to Speech SDK 1.14.0 or higher\n\n    source.createAudioContext = function () {\n      if (!!source.privContext) {\n        return;\n      }\n\n      var AudioContext = window.AudioContext || window.webkitAudioContext;\n\n      if (typeof AudioContext === 'undefined') {\n        throw new Error('Browser does not support Web Audio API (AudioContext/webkitAudioContext is not available).');\n      }\n\n      if (navigator.mediaDevices.getSupportedConstraints().sampleRate) {\n        source.privContext = new AudioContext({\n          sampleRate: _MicAudioSource.MicAudioSource.AUDIOFORMAT.samplesPerSec\n        });\n      } else {\n        source.privContext = new AudioContext();\n      }\n    }; // This piece of code is adopted from microsoft-cognitiveservices-speech-sdk/common.browser/MicAudioSource.ts.\n    // Instead of closing the AudioContext, it will just suspend it. And the next time it is needed, it will be resumed (by the original code).\n\n\n    source.destroyAudioContext = function () {\n      if (!source.privContext) {\n        return;\n      }\n\n      source.privRecorder.releaseMediaResources(source.privContext);\n      source.privContext.state === 'running' && source.privContext.suspend();\n    };\n  }\n\n  return function () {\n    var _ref3 = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {},\n        referenceGrammarID = _ref3.referenceGrammarID;\n\n    var _createPonyfill = (0, _SpeechServices.default)({\n      audioConfig: audioConfig,\n      audioContext: audioContext,\n      credentials: credentials,\n      enableTelemetry: enableTelemetry,\n      referenceGrammars: referenceGrammarID ? [\"luis/\".concat(referenceGrammarID, \"-PRODUCTION\")] : [],\n      speechRecognitionEndpointId: speechRecognitionEndpointId,\n      speechSynthesisDeploymentId: speechSynthesisDeploymentId,\n      speechSynthesisOutputFormat: speechSynthesisOutputFormat,\n      textNormalization: textNormalization\n    }),\n        SpeechGrammarList = _createPonyfill.SpeechGrammarList,\n        SpeechRecognition = _createPonyfill.SpeechRecognition,\n        speechSynthesis = _createPonyfill.speechSynthesis,\n        SpeechSynthesisUtterance = _createPonyfill.SpeechSynthesisUtterance;\n\n    return {\n      SpeechGrammarList: SpeechGrammarList,\n      SpeechRecognition: SpeechRecognition,\n      speechSynthesis: speechSynthesis,\n      SpeechSynthesisUtterance: SpeechSynthesisUtterance\n    };\n  };\n}","map":{"version":3,"sources":["../src/createCognitiveServicesSpeechServicesPonyfillFactory.js"],"names":["fnOrValue","audioConfig","audioContext","audioInputDeviceId","authorizationToken","credentials","enableTelemetry","region","speechRecognitionEndpointId","speechSynthesisDeploymentId","speechSynthesisOutputFormat","subscriptionKey","textNormalization","window","console","resolveFunction","AudioConfig","source","AudioContext","navigator","sampleRate","MicAudioSource","samplesPerSec","referenceGrammarID","SpeechGrammarList","SpeechRecognition","speechSynthesis","SpeechSynthesisUtterance","referenceGrammars"],"mappings":";;;;;;;;;;;;;AAAA,IAAA,YAAA,GAAA,OAAA,CAAA,8EAAA,CAAA;;AACA,IAAA,eAAA,GAAA,OAAA,CAAA,sFAAA,CAAA;;AACA,IAAA,eAAA,GAAA,sBAAA,CAAA,OAAA,CAAA,kDAAA,CAAA,CAAA;;AAEA,SAAA,eAAA,CAAA,SAAA,EAAoC;AAClC,SAAO,OAAA,SAAA,KAAA,UAAA,GAAkCA,SAAlC,EAAA,GAAP,SAAA;AACD;;AAEc,SAAA,oDAAA,CAAA,IAAA,EAaZ;AAAA,MAZDC,WAYC,GAAA,IAAA,CAZDA,WAYC;AAAA,MAXDC,YAWC,GAAA,IAAA,CAXDA,YAWC;AAAA,MAVDC,kBAUC,GAAA,IAAA,CAVDA,kBAUC;AAAA,MATDC,kBASC,GAAA,IAAA,CATDA,kBASC;AAAA,MARDC,WAQC,GAAA,IAAA,CARDA,WAQC;AAAA,MAPDC,eAOC,GAAA,IAAA,CAPDA,eAOC;AAAA,MANDC,MAMC,GAAA,IAAA,CANDA,MAMC;AAAA,MALDC,2BAKC,GAAA,IAAA,CALDA,2BAKC;AAAA,MAJDC,2BAIC,GAAA,IAAA,CAJDA,2BAIC;AAAA,MAHDC,2BAGC,GAAA,IAAA,CAHDA,2BAGC;AAAA,MAFDC,eAEC,GAAA,IAAA,CAFDA,eAEC;AAAA,MADDC,iBACC,GAAA,IAAA,CADDA,iBACC;;AACD,MAAI,CAACC,MAAM,CAANA,SAAAA,CAAD,YAAA,IAAkC,CAAtC,WAAA,EAAoD;AAClDC,IAAAA,OAAO,CAAPA,IAAAA,CAAAA,kPAAAA;AAIA,WAAO,YAAA;AAAA,aAAA,EAAA;AAAP,KAAA;AACD;;AAED,MAAI,CAAA,WAAA,KAAiBV,kBAAkB,IAAlBA,MAAAA,IAArB,eAAI,CAAJ,EAAuE;AACrEU,IAAAA,OAAO,CAAPA,IAAAA,CAAAA,0KAAAA;;AAIAT,IAAAA,WAAW,GAAA,aAAA,YAAA;AAAA,UAAA,KAAA,GAAA,CAAA,GAAA,kBAAA,CAAA,OAAA,GAAA,aAAA,YAAA,CAAA,OAAA,CAAA,IAAA,CAAG,SAAA,OAAA,GAAA;AAAA,eAAA,YAAA,CAAA,OAAA,CAAA,IAAA,CAAA,SAAA,QAAA,CAAA,QAAA,EAAA;AAAA,iBAAA,CAAA,EAAA;AAAA,oBAAA,QAAA,CAAA,IAAA,GAAA,QAAA,CAAA,IAAA;AAAA,mBAAA,CAAA;AAAA,oBAAA,CAAA,kBAAA,EAAA;AAAA,kBAAA,QAAA,CAAA,IAAA,GAAA,CAAA;AAAA;AAAA;;AAAA,gBAAA,QAAA,CAAA,IAAA,GAAA,CAAA;AAAA,uBAGkBU,eAAe,CAHjC,kBAGiC,CAHjC;;AAAA,mBAAA,CAAA;AAAA,gBAAA,QAAA,CAAA,EAAA,GAAA,QAAA,CAAA,IAAA;AAAA,gBAAA,QAAA,CAAA,EAAA,GAAA,MAAA;AAAA,uBAAA,QAAA,CAAA,MAAA,CAAA,QAAA,EAAA;AAGRX,kBAAAA,kBAHQ,EAAA,QAAA,CAAA,EAAA;AAIRG,kBAAAA,MAJQ,EAAA,QAAA,CAAA;AAAA,iBAAA,CAAA;;AAAA,mBAAA,CAAA;AAAA,gBAAA,QAAA,CAAA,EAAA,GAAA,MAAA;AAAA,gBAAA,QAAA,CAAA,IAAA,GAAA,CAAA;AAAA,uBAUaQ,eAAe,CAV5B,eAU4B,CAV5B;;AAAA,mBAAA,CAAA;AAAA,gBAAA,QAAA,CAAA,EAAA,GAAA,QAAA,CAAA,IAAA;AAAA,uBAAA,QAAA,CAAA,MAAA,CAAA,QAAA,EAAA;AASVR,kBAAAA,MATU,EAAA,QAAA,CAAA,EAAA;AAUVI,kBAAAA,eAVU,EAAA,QAAA,CAAA;AAAA,iBAAA,CAAA;;AAAA,mBAAA,EAAA;AAAA,mBAAA,KAAA;AAAA,uBAAA,QAAA,CAAA,IAAA,EAAA;AAAA;AAAA;AAAA,SAAA,EAAA,OAAA,CAAA;AAAH,OAAA,CAAA,CAAA;;AAAA,aAAA,SAAA,WAAA,GAAA;AAAA,eAAA,KAAA,CAAA,KAAA,CAAA,IAAA,EAAA,SAAA,CAAA;AAAA,OAAA;AAAXN,KAAW,EAAXA;AAaD;;AAED,MAAIJ,WAAW,IAAf,kBAAA,EAAuC;AACrCa,IAAAA,OAAO,CAAPA,IAAAA,CAAAA,6HAAAA;AA9BD,GAAA,CAmCD;AACA;AACA;;;AACA,MAAI,CAAJ,WAAA,EAAkB;AAChBb,IAAAA,WAAW,GAAGE,kBAAkB,GAC5Ba,YAAAA,CAAAA,WAAAA,CAAAA,mBAAAA,CAD4B,kBAC5BA,CAD4B,GAE5BA,YAAAA,CAAAA,WAAAA,CAFJf,0BAEIe,EAFJf;AAIA,QAAMgB,MAAM,GAAGhB,WAAW,CALV,UAKhB,CALgB,CAOhB;AACA;AACA;AACA;;AACAgB,IAAAA,MAAM,CAANA,kBAAAA,GAA4B,YAAM;AAChC,UAAI,CAAC,CAACA,MAAM,CAAZ,WAAA,EAA0B;AACxB;AACD;;AAED,UAAMC,YAAY,GAAGL,MAAM,CAANA,YAAAA,IAAuBA,MAAM,CAAlD,kBAAA;;AAEA,UAAI,OAAA,YAAA,KAAJ,WAAA,EAAyC;AACvC,cAAM,IAAA,KAAA,CAAN,4FAAM,CAAN;AACD;;AAED,UAAIM,SAAS,CAATA,YAAAA,CAAAA,uBAAAA,GAAJ,UAAA,EAAiE;AAC/DF,QAAAA,MAAM,CAANA,WAAAA,GAAqB,IAAA,YAAA,CAAiB;AAAEG,UAAAA,UAAU,EAAEC,eAAAA,CAAAA,cAAAA,CAAAA,WAAAA,CAA2BC;AAAzC,SAAjB,CAArBL;AADF,OAAA,MAEO;AACLA,QAAAA,MAAM,CAANA,WAAAA,GAAqB,IAArBA,YAAqB,EAArBA;AACD;AA1Ba,KAWhBA,CAXgB,CA6BhB;AACA;;;AACAA,IAAAA,MAAM,CAANA,mBAAAA,GAA6B,YAAM;AACjC,UAAI,CAACA,MAAM,CAAX,WAAA,EAAyB;AACvB;AACD;;AAEDA,MAAAA,MAAM,CAANA,YAAAA,CAAAA,qBAAAA,CAA0CA,MAAM,CAAhDA,WAAAA;AACAA,MAAAA,MAAM,CAANA,WAAAA,CAAAA,KAAAA,KAAAA,SAAAA,IAA0CA,MAAM,CAANA,WAAAA,CAA1CA,OAA0CA,EAA1CA;AANFA,KAAAA;AAQD;;AAED,SAAO,YAAiC;AAAA,QAAA,KAAA,GAAA,SAAA,CAAA,MAAA,GAAA,CAAA,IAAA,SAAA,CAAA,CAAA,CAAA,KAAA,SAAA,GAAA,SAAA,CAAA,CAAA,CAAA,GAAP,EAAO;AAAA,QAA9BM,kBAA8B,GAAA,KAAA,CAA9BA,kBAA8B;;AAAA,QAAA,eAAA,GACsD,CAAA,GAAA,eAAA,CAAA,OAAA,EAAe;AACzGtB,MAAAA,WAAW,EAD8F,WAAA;AAEzGC,MAAAA,YAAY,EAF6F,YAAA;AAGzGG,MAAAA,WAAW,EAH8F,WAAA;AAIzGC,MAAAA,eAAe,EAJ0F,eAAA;AAKzGsB,MAAAA,iBAAiB,EAAEL,kBAAkB,GAAG,CAAA,QAAA,MAAA,CAAA,kBAAA,EAAH,aAAG,CAAA,CAAH,GALoE,EAAA;AAMzGf,MAAAA,2BAA2B,EAN8E,2BAAA;AAOzGC,MAAAA,2BAA2B,EAP8E,2BAAA;AAQzGC,MAAAA,2BAA2B,EAR8E,2BAAA;AASzGE,MAAAA,iBAAiB,EAAjBA;AATyG,KAAf,CADtD;AAAA,QAC9BY,iBAD8B,GAAA,eAAA,CAAA,iBAAA;AAAA,QACXC,iBADW,GAAA,eAAA,CAAA,iBAAA;AAAA,QACQC,eADR,GAAA,eAAA,CAAA,eAAA;AAAA,QACyBC,wBADzB,GAAA,eAAA,CAAA,wBAAA;;AAatC,WAAO;AACLH,MAAAA,iBAAiB,EADZ,iBAAA;AAELC,MAAAA,iBAAiB,EAFZ,iBAAA;AAGLC,MAAAA,eAAe,EAHV,eAAA;AAILC,MAAAA,wBAAwB,EAAxBA;AAJK,KAAP;AAbF,GAAA;AAoBD","sourcesContent":["import { AudioConfig } from 'microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioConfig';\nimport { MicAudioSource } from 'microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/MicAudioSource';\nimport createPonyfill from 'web-speech-cognitive-services/lib/SpeechServices';\n\nfunction resolveFunction(fnOrValue) {\n  return typeof fnOrValue === 'function' ? fnOrValue() : fnOrValue;\n}\n\nexport default function createCognitiveServicesSpeechServicesPonyfillFactory({\n  audioConfig,\n  audioContext,\n  audioInputDeviceId,\n  authorizationToken,\n  credentials,\n  enableTelemetry,\n  region,\n  speechRecognitionEndpointId,\n  speechSynthesisDeploymentId,\n  speechSynthesisOutputFormat,\n  subscriptionKey,\n  textNormalization\n}) {\n  if (!window.navigator.mediaDevices && !audioConfig) {\n    console.warn(\n      'botframework-webchat: Your browser does not support Web Audio or the page is not loaded via HTTPS or localhost. Cognitive Services Speech Services is disabled. However, you may pass a custom AudioConfig to enable speech in this environment.'\n    );\n\n    return () => ({});\n  }\n\n  if (!credentials && (authorizationToken || region || subscriptionKey)) {\n    console.warn(\n      'botframework-webchat: \"authorizationToken\", \"region\", and \"subscriptionKey\" are deprecated and will be removed on or after 2020-12-17. Please use \"credentials\" instead.'\n    );\n\n    credentials = async () => {\n      if (authorizationToken) {\n        return {\n          authorizationToken: await resolveFunction(authorizationToken),\n          region\n        };\n      }\n\n      return {\n        region,\n        subscriptionKey: await resolveFunction(subscriptionKey)\n      };\n    };\n  }\n\n  if (audioConfig && audioInputDeviceId) {\n    console.warn(\n      'botframework-webchat: \"audioConfig\" and \"audioInputDeviceId\" cannot be set at the same time; ignoring \"audioInputDeviceId\".'\n    );\n  }\n\n  // WORKAROUND: We should prevent AudioContext object from being recreated because they may be blessed and UX-wise expensive to recreate.\n  //             In Cognitive Services SDK, if they detect the \"end\" function is falsy, they will not call \"end\" but \"suspend\" instead.\n  //             And on next recognition, they will re-use the AudioContext object.\n  if (!audioConfig) {\n    audioConfig = audioInputDeviceId\n      ? AudioConfig.fromMicrophoneInput(audioInputDeviceId)\n      : AudioConfig.fromDefaultMicrophoneInput();\n\n    const source = audioConfig.privSource;\n\n    // WORKAROUND: In Speech SDK 1.12.0-1.13.1, it dropped support of macOS/iOS Safari.\n    //             This code is adopted from microsoft-cognitiveservices-speech-sdk/src/common.browser/MicAudioSource.ts.\n    //             We will not need this code when using Speech SDK 1.14.0 or up.\n    // TODO: [P1] #3575 Remove the following lines when bumping to Speech SDK 1.14.0 or higher\n    source.createAudioContext = () => {\n      if (!!source.privContext) {\n        return;\n      }\n\n      const AudioContext = window.AudioContext || window.webkitAudioContext;\n\n      if (typeof AudioContext === 'undefined') {\n        throw new Error('Browser does not support Web Audio API (AudioContext/webkitAudioContext is not available).');\n      }\n\n      if (navigator.mediaDevices.getSupportedConstraints().sampleRate) {\n        source.privContext = new AudioContext({ sampleRate: MicAudioSource.AUDIOFORMAT.samplesPerSec });\n      } else {\n        source.privContext = new AudioContext();\n      }\n    };\n\n    // This piece of code is adopted from microsoft-cognitiveservices-speech-sdk/common.browser/MicAudioSource.ts.\n    // Instead of closing the AudioContext, it will just suspend it. And the next time it is needed, it will be resumed (by the original code).\n    source.destroyAudioContext = () => {\n      if (!source.privContext) {\n        return;\n      }\n\n      source.privRecorder.releaseMediaResources(source.privContext);\n      source.privContext.state === 'running' && source.privContext.suspend();\n    };\n  }\n\n  return ({ referenceGrammarID } = {}) => {\n    const { SpeechGrammarList, SpeechRecognition, speechSynthesis, SpeechSynthesisUtterance } = createPonyfill({\n      audioConfig,\n      audioContext,\n      credentials,\n      enableTelemetry,\n      referenceGrammars: referenceGrammarID ? [`luis/${referenceGrammarID}-PRODUCTION`] : [],\n      speechRecognitionEndpointId,\n      speechSynthesisDeploymentId,\n      speechSynthesisOutputFormat,\n      textNormalization\n    });\n\n    return {\n      SpeechGrammarList,\n      SpeechRecognition,\n      speechSynthesis,\n      SpeechSynthesisUtterance\n    };\n  };\n}\n"],"sourceRoot":"bundle:///"},"metadata":{},"sourceType":"script"}